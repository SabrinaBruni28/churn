{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5656d477-c403-4f57-8641-f7fdf240cda3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "np.seterr(divide = 'ignore') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744c98e-9789-44d6-89a0-30c81dbc4167",
   "metadata": {},
   "source": [
    "## Declaração das Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565ddcf9-6535-4209-a41d-c027555f6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import BetaGeoFitter\n",
    "\n",
    "# Função para criar o modelo BG/NBD\n",
    "def criarModeloBGF(dadosRFM #Dataset já processado pelo RFM\n",
    "                   ,teste = True #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                   ,penalizer = 0.01# Coeficiente de penalização usado pelo modelo\n",
    "                  ):\n",
    "    # instantiation of BG-NBD model\n",
    "    bgf = BetaGeoFitter(penalizer_coef=penalizer)\n",
    "\n",
    "    # fitting of BG-NBD model\n",
    "    if teste:\n",
    "        bgf.fit(frequency=dadosRFM['frequency_cal'],\n",
    "                recency=dadosRFM['recency_cal'],\n",
    "                T=dadosRFM['T_cal'])\n",
    "    else:\n",
    "        bgf.fit(frequency=dadosRFM['frequency'],\n",
    "                recency=dadosRFM['recency'],\n",
    "                T=dadosRFM['T'])\n",
    "\n",
    "    return bgf\n",
    "\n",
    "#Dado um período, retorna o número de transações esperadas até lá\n",
    "def comprasEsperadas(model #Modelo BG/NBD ou de Pareto esperado para realizar a predição\n",
    "                     ,rfm #Dataset já processado pelo RFM\n",
    "                     ,numPeriodos = 180 #Numero de períodos em dia para que deseja efetuar a predição\n",
    "                     , teste = True #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                    ):\n",
    "    if teste:\n",
    "        return model.conditional_expected_number_of_purchases_up_to_time(numPeriodos, rfm['frequency_cal'].values, rfm['recency_cal'].values, rfm['T_cal'].values)\n",
    "    return model.conditional_expected_number_of_purchases_up_to_time(numPeriodos, rfm['frequency'].values, rfm['recency'].values, rfm['T'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a86b8511-e228-4a75-b460-acb7d8baa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPeriodosList(df, dateColumn = \"date\",frequencia = \"W\"):\n",
    "    def to_period(d):\n",
    "        return d.to_period(frequencia)\n",
    "        \n",
    "    df[\"period\"] = df[dateColumn].map(to_period)\n",
    "    df = df.sort_values(by='period')\n",
    "    return df.period.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658a11f9-7274-4155-863c-33368662b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes.utils import calibration_and_holdout_data,summary_data_from_transaction_data\n",
    "\n",
    "\n",
    "#Processa um dataset de acordo com o padrão RFMT\n",
    "# O retorno desta função consiste em:\n",
    "#Se teste for true : Retorna o dataset considerando a data de divisão para dividir o período de 'calibração' e 'holdout'.\n",
    "#Se for falso: Retorna todo o dataset processado pelo padrão RFMT.\n",
    "def RFM_Progressivo(df #Dataframe que será feito\n",
    "                 ,colunaID #Nome da coluna onde encontra-se os identificadores\n",
    "                 ,colunaData  #Nome da coluna onde encontra-se as datas\n",
    "                 ,colunaValor  #Nome da coluna onde encontra-se os valores monetários\n",
    "                 ,frequencia = 'W' #Frequência em que será observado, Ex: \"W\" - Weeks\n",
    "                 ,calibrationEnd = None #Caso queira passar a data do fim do período de calibração\n",
    "                 ,ObservationEnd = None #Caso queira passar a data do fim do período de Obsersvação\n",
    "                 ,minTrainTime = 20 # Porcentagem da divisão dos dados para separar em Obsersvação e calibração\n",
    "                ,intervalosPredicao = 4\n",
    "                 , teste = True #Verdadeiro caso queira separar os dados em Obsersvação e calibração\n",
    "                ):\n",
    "    #arquivo.close()\n",
    "    if calibrationEnd == None:\n",
    "        periodos = getPeriodosList(df,colunaData,frequencia)\n",
    "        calibrationEnd = periodos[minTrainTime].to_timestamp()\n",
    "        ObservationEnd = periodos[minTrainTime+intervalosPredicao].to_timestamp()\n",
    "        \n",
    "    if teste == False:\n",
    "        return summary_data_from_transaction_data(transactions=df,\n",
    "                                                  customer_id_col=colunaID, \n",
    "                                                   datetime_col=colunaData,\n",
    "                                                   monetary_value_col = colunaValor,\n",
    "                                                   freq=frequencia)\n",
    "    else:\n",
    "        rfm_cal_holdout = calibration_and_holdout_data(transactions=df,\n",
    "                                                  customer_id_col=colunaID, \n",
    "                                                   datetime_col=colunaData,\n",
    "                                                   monetary_value_col = colunaValor,\n",
    "                                                   freq=frequencia,\n",
    "                                                   calibration_period_end=calibrationEnd,\n",
    "                                                   observation_period_end=ObservationEnd)\n",
    "        return rfm_cal_holdout\n",
    "\n",
    "#rfm = RFM_Progressivo(df,'customer_index','date','amount',teste=True)\n",
    "#rfm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb75dca1-7529-4de5-9e62-6c570f97d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error,mean_absolute_error\n",
    "\n",
    "#Função utilizada para criar os modelos de regressão\n",
    "#Retorna o MSE e o modelo\n",
    "def createModelRegressor(RegressorModel #Modelo que será treinado (Tem de ter a função fit e predict implementadas)\n",
    "                         , X_train #Dados que serão usados para o treino\n",
    "                         , X_test #Dados que serão usados para o teste\n",
    "                         , Y_train #Targets dos dados de treino\n",
    "                         , Y_test #Targets dos dados de testes\n",
    "                        ): \n",
    "    regressor = RegressorModel\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    pred = regressor.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, pred) #Utilizando o MSE, caso queira outra métrica, trocar nesta parte!\n",
    "    return mse, regressor #Retorna o MSE e o Regressor\n",
    "\n",
    "\n",
    "#Função feita para escolher o melhor modelo de acordo com a situação\n",
    "#Retorna o melho modelo para a situação\n",
    "def escolheModelo(dfRFM #Dataframe já processado pelo RFM\n",
    "                  ,target = 'monetary_value_holdout' #Nome da coluna de target, sendo a coluna de valor monetário prevista ou frequência\n",
    "                  , tunning = False #Caso queira fazer o Tunning de hyperparâmetros, deixar como true\n",
    "                 ):\n",
    "    #Colunas utilizadas para treino\n",
    "    Xcol = ['frequency', 'recency', 'T', 'monetary_value']\n",
    "    #Colunas utilizadas para target\n",
    "    Ycol = [target]\n",
    "\n",
    "    X = dfRFM[Xcol]\n",
    "    Y = dfRFM[Ycol]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X.values, np.ravel(Y.values), random_state=42)\n",
    "    \n",
    "    if tunning == False:\n",
    "        lasso = LassoCV()\n",
    "        Enet = ElasticNet()\n",
    "        rf = RandomForestRegressor()\n",
    "        krr = KernelRidge()\n",
    "        GBoost = GradientBoostingRegressor()\n",
    "        HGBoost = HistGradientBoostingRegressor()\n",
    "        model_xgb = xgb.XGBRegressor()\n",
    "        model_lgb = lgb.LGBMRegressor(objective='regression',verbose=-1)\n",
    "    \n",
    "    else:\n",
    "        #lasso = LassoCV()\n",
    "        grid = {'n_alphas' : [100,200,500,100],'max_iter' : [1000,1500,2000], 'random_state' : [42]}\n",
    "        lasso = GridSearchCV(estimator=LassoCV(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "        grid = {\"max_iter\": [1000,1500,2000],\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\"l1_ratio\": np.arange(0.0, 1.0, 0.1), 'random_state' : [42]}\n",
    "        Enet = GridSearchCV(estimator=ElasticNet(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #Enet = ElasticNet()\n",
    "\n",
    "        grid = {'bootstrap': [True, False],'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [200, 800, 1000],'random_state' : [42]}    \n",
    "        rf = GridSearchCV(estimator=RandomForestRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #rf = RandomForestRegressor()\n",
    "\n",
    "        grid = {\"alpha\": [0.001, 0.01, 0.1, 1,], \"coef0\" : [0.01,0.1,1,10,100] ,'degree_': [1,3,5,10],'random_state':[42]}\n",
    "        krr = GridSearchCV(estimator=KernelRidge(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #krr = KernelRidge()\n",
    "\n",
    "        grid = {'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1],'max_depth':[1,2,4],'subsample':[.5,.75,1],'random_state':[42]}\n",
    "        GBoost = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #GBoost = GradientBoostingRegressor()\n",
    "        grid = {'learning_rate':[.001,0.01,.1],'max_depth':[1,2,4,None],'max_leaf_nodes' : [31,None],'random_state':[42]}\n",
    "\n",
    "        HGBoost = GridSearchCV(estimator=HistGradientBoostingRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #HGBoost = HistGradientBoostingRegressor()\n",
    "\n",
    "        grid = { 'max_depth': [3,6,10],'learning_rate': [0.01, 0.05, 0.1],'n_estimators': [100, 500, 1000],'colsample_bytree': [0.3, 0.7],'random_state':[42]}\n",
    "        #model_xgb = xgb.XGBRegressor()\n",
    "        model_xgb = GridSearchCV(estimator=xgb.XGBRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #model_lgb = lgb.LGBMRegressor(objective='regression')\n",
    "        model_lgb =GridSearchCV(estimator=lgb.LGBMRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "    \n",
    "    \n",
    "    models = [lasso, Enet, rf, GBoost, HGBoost, model_xgb, model_lgb]#,krr]\n",
    "    bestModel, bestScore = None, None\n",
    "    for i in models:\n",
    "        score = createModelRegressor(i, X_train, X_test, Y_train, Y_test)\n",
    "        if bestScore == None or bestScore > score[0]:\n",
    "            bestScore, bestModel = score\n",
    "        if tunning:\n",
    "            pass\n",
    "            #print(type(i.best_estimator_).__name__, \" mse: {:.4f} \\n\".format(score[0]))\n",
    "        else:\n",
    "            print(type(i).__name__, \" mse: {:.4f} \\n\".format(score[0]))\n",
    "            #pass\n",
    "\n",
    "    if tunning :\n",
    "        return bestModel.best_estimator_\n",
    "    else:\n",
    "        return bestModel\n",
    "    #prediction = bestModel.predict(X_test[Xcol])\n",
    "    #X_test['ExpectedML'] = prediction\n",
    "    #X_test['Real Expected'] = Y_test\n",
    "    #return X_test\n",
    "\n",
    "\n",
    "\n",
    "def escolheModeloCustom(X_train, X_test, Y_train, Y_test#\n",
    "                  ,target = 'monetary_value_holdout' #Nome da coluna de target, sendo a coluna de valor monetário prevista ou frequência\n",
    "                  , tunning = False #Caso queira fazer o Tunning de hyperparâmetros, deixar como true\n",
    "                 ):\n",
    "\n",
    "    if tunning == False:\n",
    "        lasso = LassoCV()\n",
    "        Enet = ElasticNet()\n",
    "        rf = RandomForestRegressor()\n",
    "        krr = KernelRidge()\n",
    "        GBoost = GradientBoostingRegressor()\n",
    "        HGBoost = HistGradientBoostingRegressor()\n",
    "        model_xgb = xgb.XGBRegressor()\n",
    "        model_lgb = lgb.LGBMRegressor(objective='regression',verbose=-1)\n",
    "    \n",
    "    else:\n",
    "        #lasso = LassoCV()\n",
    "        grid = {'n_alphas' : [100,200,500,100],'max_iter' : [1000,1500,2000], 'random_state' : [42]}\n",
    "        lasso = GridSearchCV(estimator=LassoCV(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "        grid = {\"max_iter\": [1000,1500,2000],\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\"l1_ratio\": np.arange(0.0, 1.0, 0.1), 'random_state' : [42]}\n",
    "        Enet = GridSearchCV(estimator=ElasticNet(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #Enet = ElasticNet()\n",
    "\n",
    "        grid = {'bootstrap': [True, False],'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [200, 800, 1000],'random_state' : [42]}    \n",
    "        rf = GridSearchCV(estimator=RandomForestRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #rf = RandomForestRegressor()\n",
    "\n",
    "        grid = {\"alpha\": [0.001, 0.01, 0.1, 1,], \"coef0\" : [0.01,0.1,1,10,100] ,'degree_': [1,3,5,10],'random_state':[42]}\n",
    "        krr = GridSearchCV(estimator=KernelRidge(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #krr = KernelRidge()\n",
    "\n",
    "        grid = {'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1],'max_depth':[1,2,4],'subsample':[.5,.75,1],'random_state':[42]}\n",
    "        GBoost = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #GBoost = GradientBoostingRegressor()\n",
    "        grid = {'learning_rate':[.001,0.01,.1],'max_depth':[1,2,4,None],'max_leaf_nodes' : [31,None],'random_state':[42]}\n",
    "\n",
    "        HGBoost = GridSearchCV(estimator=HistGradientBoostingRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #HGBoost = HistGradientBoostingRegressor()\n",
    "\n",
    "        grid = { 'max_depth': [3,6,10],'learning_rate': [0.01, 0.05, 0.1],'n_estimators': [100, 500, 1000],'colsample_bytree': [0.3, 0.7],'random_state':[42]}\n",
    "        #model_xgb = xgb.XGBRegressor()\n",
    "        model_xgb = GridSearchCV(estimator=xgb.XGBRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        #model_lgb = lgb.LGBMRegressor(objective='regression')\n",
    "        model_lgb =GridSearchCV(estimator=lgb.LGBMRegressor(), param_grid=grid, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "    \n",
    "    \n",
    "    models = [lasso, Enet, rf, GBoost, HGBoost, model_xgb, model_lgb]#,krr]\n",
    "    bestModel, bestScore = None, None\n",
    "    for i in models:\n",
    "        score = createModelRegressor(i, X_train, X_test, Y_train, Y_test)\n",
    "        if bestScore == None or bestScore > score[0]:\n",
    "            bestScore, bestModel = score\n",
    "        if tunning:\n",
    "            pass\n",
    "            #print(type(i.best_estimator_).__name__, \" mse: {:.4f} \\n\".format(score[0]))\n",
    "        else:\n",
    "            #print(type(i).__name__, \" mse: {:.4f} \\n\".format(score[0]))\n",
    "            pass\n",
    "\n",
    "    if tunning :\n",
    "        return bestModel.best_estimator_\n",
    "    else:\n",
    "        return bestModel\n",
    "\n",
    "\n",
    "#escolheModelo(rfm,target = 'frequency_holdout')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a159e5a-92ac-4805-84ea-f02059fdfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBauerDatasetSplitTimes(timeCol,outputSize):\n",
    "  vals = timeCol.unique()\n",
    "  max_data = timeCol.max()\n",
    "  training_start = vals[0]\n",
    "  training_end   = vals[max_data - (outputSize*2) - 1]\n",
    "  holdout_start  = vals[max_data - (outputSize*2)]\n",
    "  holdout_end    = vals[max_data - outputSize]\n",
    "  return training_start,training_end,holdout_start,holdout_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8baca6-ef67-4ca2-af78-a8ea93fd4b89",
   "metadata": {},
   "source": [
    "### Modelos Eniac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c7fc38-c410-4ef4-9d12-93c5256b4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import BetaGeoFitter\n",
    "from lifetimes import ParetoNBDFitter\n",
    "from lifetimes import GammaGammaFitter\n",
    "\n",
    "\n",
    "# Função para criar o modelo BG/NBD\n",
    "def criarModeloBGF(dadosRFM #Dataset já processado pelo RFM\n",
    "                   ,teste = True #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                   ,penalizer = 0.1# Coeficiente de penalização usado pelo modelo\n",
    "                  ):\n",
    "    # instantiation of BG-NBD model\n",
    "    bgf = BetaGeoFitter(penalizer_coef=penalizer)\n",
    "\n",
    "    # fitting of BG-NBD model\n",
    "    if teste:\n",
    "        bgf.fit(frequency=dadosRFM['frequency_cal'],\n",
    "                recency=dadosRFM['recency_cal'],\n",
    "                T=dadosRFM['T_cal'])\n",
    "    else:\n",
    "        bgf.fit(frequency=dadosRFM['frequency'],\n",
    "                recency=dadosRFM['recency'],\n",
    "                T=dadosRFM['T'])\n",
    "\n",
    "    return bgf\n",
    "\n",
    "\n",
    "# Função para criar o modelo de Pareto/NBD\n",
    "def criarModeloPareto(dadosRFM #Dataset já processado pelo RFM\n",
    "                      ,teste = True  #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                      ,penalizer = 0.1# Coeficiente de penalização usado pelo modelo\n",
    "):\n",
    "    # instantiation of Pareto model\n",
    "    pareto = ParetoNBDFitter(penalizer_coef=penalizer)\n",
    "\n",
    "    # fitting of the model\n",
    "    if teste:\n",
    "        pareto.fit(frequency=dadosRFM['frequency_cal'],\n",
    "                recency=dadosRFM['recency_cal'],\n",
    "                T=dadosRFM['T_cal'])\n",
    "    else:\n",
    "        pareto.fit(frequency=dadosRFM['frequency'],\n",
    "                recency=dadosRFM['recency'],\n",
    "                T=dadosRFM['T'])\n",
    "\n",
    "    return pareto\n",
    "\n",
    "\n",
    "#Função para criar o modelo que prevê o valor monetário médio de cada cliente, usando o modelo Gamma Gamma.\n",
    "#Retorna o dataset com a coluna 'ExpectedGammaGamma'\n",
    "def preverValorGGF(rfm, #Dataset já processado pelo RFM\n",
    "                   coefPenalizacao = 0.01, #Coeficiente de penalização utilizada pelo Gamma Gamma\n",
    "                   teste = True #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                  ):\n",
    "    monetary = \"monetary_value\"\n",
    "    frequency = \"frequency\"\n",
    "    if teste:\n",
    "        monetary = \"monetary_value_cal\"\n",
    "        frequency = \"frequency_cal\"\n",
    "    ggf = GammaGammaFitter(coefPenalizacao)\n",
    "    \n",
    "    rfm = rfm[rfm[monetary] > 0]\n",
    "    rfm = rfm[rfm[frequency] > 0]\n",
    "\n",
    "    ggf.fit(rfm[frequency],rfm[monetary])\n",
    "    return ggf\n",
    "\n",
    "\n",
    "#Dado um período, retorna o número de transações esperadas até lá\n",
    "def comprasEsperadas(model #Modelo BG/NBD ou de Pareto esperado para realizar a predição\n",
    "                     ,rfm #Dataset já processado pelo RFM\n",
    "                     ,numPeriodos = 180 #Numero de períodos em dia para que deseja efetuar a predição\n",
    "                     , teste = True #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                    ):\n",
    "    if teste:\n",
    "        return model.conditional_expected_number_of_purchases_up_to_time(numPeriodos, rfm['frequency_cal'].values, rfm['recency_cal'].values, rfm['T_cal'].values)\n",
    "    return model.conditional_expected_number_of_purchases_up_to_time(numPeriodos, rfm['frequency'].values, rfm['recency'].values, rfm['T'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f14410f-8177-43c2-89fe-d0bc6518888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def testarModelosPredicaoCumulativa(df,\n",
    "                                    minTraining = 16, #Qual é o periodo mínimo que será usado para treino\n",
    "                                    maxTraining = 40, #Qual será o último período que será usado para o treino\n",
    "                                    intervalosPredicao = 4, #Define quantos períodos serão os intervalos de predição\n",
    "                                    cID = \"customer_index\", #Nome da coluna contendo o ID dos clientes\n",
    "                                    cDate = \"date\",#Nome da coluna onde contém a data das compras\n",
    "                                    cMonetary = 'amount', #Nome da coluna onde contém a média dos valores monetários\n",
    "                                    frequencia = \"s\",\n",
    "                                    calculateTransactions = True,\n",
    "                                    calculateMonetary = True,\n",
    "                                    penalizer = 0.01\n",
    "                                   ):\n",
    "    \n",
    "\n",
    "    dfResultados =  summary_data_from_transaction_data(df[df[\"WeekID\"] <= maxTraining], \n",
    "                                                    cID, \n",
    "                                                    cDate, \n",
    "                                                    monetary_value_col = cMonetary,freq = frequencia).reset_index()[[cID]].set_index(cID)\n",
    "\n",
    "    \n",
    "    for periodo in range(minTraining,maxTraining,intervalosPredicao):\n",
    "        calibrationDate = periodo #8\n",
    "        #Validar com os próximos intervalos.\n",
    "        validationEnd = periodo + intervalosPredicao       #12 \n",
    "        predictDate = periodo + (intervalosPredicao*2)    #16\n",
    "        print(calibrationDate,validationEnd,predictDate)   \n",
    "\n",
    "\n",
    "        XTrain = summary_data_from_transaction_data(df[df[\"WeekID\"] <= calibrationDate], \n",
    "                                                   cID, cDate, \n",
    "                                                   monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        Ytrain = summary_data_from_transaction_data(df[df[\"WeekID\"] <= validationEnd], \n",
    "                                                    cID, \n",
    "                                                    cDate, \n",
    "                                                    monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia)\n",
    "\n",
    "        Ytrain = Ytrain.rename(columns={\"frequency\" : \"frequency_holdout\", \"monetary_value\" : \"monetary_holdout\"})[[\"frequency_holdout\",\"monetary_holdout\"]]\n",
    "\n",
    "        \n",
    "        XTest = summary_data_from_transaction_data(df[df[\"WeekID\"] <= validationEnd], cID, cDate, monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        YTest = summary_data_from_transaction_data(df[df[\"WeekID\"] <= predictDate], cID, cDate, monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        \n",
    "        YTest = YTest.rename(columns={\"frequency\" : \"frequency_holdout\", \"monetary_value\" : \"monetary_holdout\"})[[\"frequency_holdout\",\"monetary_holdout\"]]\n",
    "        \n",
    "        #XTrain = pd.concat([XTrain, Ytrain], axis=1, join=\"inner\")\n",
    "        #XTest = pd.concat([XTest, YTest], axis=1, join=\"inner\")\n",
    "        XTrain = pd.merge(XTrain, Ytrain,how='inner',left_index=True, right_index=True)\n",
    "        XTest = pd.merge(XTest, YTest,how='inner',left_index=True, right_index=True)\n",
    "        if calculateTransactions:\n",
    "            start = time.time()\n",
    "            print(f\"Periodo {periodo} de {maxTraining}\\n\\n\")\n",
    "            #print(\"Criando modelo BG/NBD\")\n",
    "            modelBGF = criarModeloBGF(XTrain, teste = False,penalizer = penalizer)\n",
    "            end = time.time()\n",
    "            print(\"Tempo BG/NBD: \",timedelta(seconds = end - start))\n",
    "            print(modelBGF)\n",
    "            start = time.time()\n",
    "           # print(\"Criando modelo Pareto\")\n",
    "            modelPareto = criarModeloPareto(XTrain,teste = False,penalizer = penalizer)\n",
    "            print(modelPareto)\n",
    "            end = time.time()\n",
    "            print(\"Tempo Pareto: \",timedelta(seconds = end - start))\n",
    "\n",
    "            start = time.time()\n",
    "            modelML = escolheModelo(XTrain,target = 'frequency_holdout')\n",
    "            end = time.time()\n",
    "            print(\"Tempo ML: \",timedelta(seconds = end - start))\n",
    "\n",
    "            \n",
    "            XTest['ExpectedMLT '+str(predictDate)] = modelML.predict(XTest[['frequency', 'recency', 'T', 'monetary_value']])\n",
    "            XTest['Real Expected Transactions'+str(predictDate)] = YTest['frequency_holdout']\n",
    "            XTest['ExpectedPareto '+str(predictDate)] = comprasEsperadas(modelPareto, XTest,numPeriodos = 7*intervalosPredicao,teste = False)\n",
    "            XTest['ExpectedBGF '+str(predictDate)] = comprasEsperadas(modelBGF, XTest,numPeriodos = 7*intervalosPredicao,teste = False)\n",
    "\n",
    "            #dfResultados[dfResultados['ExpectedML '+str(periodo + (intervalosPredicao*2))] < 0]= 0\n",
    "        if calculateMonetary:\n",
    "            ggf = preverValorGGF(XTrain, #Dataset já processado pelo RFM\n",
    "                   coefPenalizacao = penalizer, #Coeficiente de penalização utilizada pelo Gamma Gamma\n",
    "                   teste = False #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                  )\n",
    "\n",
    "            XTest['ExpectedGGF '+str(predictDate)] = ggf.conditional_expected_average_profit(XTest[\"frequency\"], XTest[\"monetary_value\"]).values\n",
    "            start = time.time()\n",
    "            modelML = escolheModelo(XTrain,target = 'monetary_holdout')\n",
    "            end = time.time()\n",
    "            print(\"Tempo MLT: \",timedelta(seconds = end - start))\n",
    "            XTest['ExpectedMLM '+str(predictDate)] = modelML.predict(XTest[['frequency', 'recency', 'T', 'monetary_value']])\n",
    "            XTest['Real Expected Monetary'+str(predictDate)] = YTest['monetary_holdout']\n",
    "\n",
    "        dfResultados = pd.merge(dfResultados,XTest.drop(['frequency', 'recency', 'T', 'monetary_value', 'frequency_holdout',\n",
    "       'monetary_holdout'], axis = 1),how = \"left\",\n",
    "                            left_index=True, right_index=True)\n",
    "            #dfResultados[dfResultados['ExpectedML '+str(periodo + (intervalosPredicao*2))] < 0]= 0    \n",
    "    return dfResultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d35fa-dfef-403f-b725-1dc0a0119383",
   "metadata": {},
   "source": [
    "### Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95d6b7-2d82-4955-876a-c9ca80fb6fea",
   "metadata": {},
   "source": [
    "### Utilizando o Prophet com a Solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9f2e460-41b0-4ddf-86e1-947d658eb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "def prophet_features(df,dateCol = \"\",monetaryCol = \"\",horizon=4):\n",
    "    temp_df = df.reset_index()\n",
    "    #temp_df = temp_df.groupby(dateCol)[monetaryCol].sum().reset_index()\n",
    "    temp_df = temp_df[[dateCol, monetaryCol]]\n",
    "    temp_df.rename(columns={dateCol: 'ds', monetaryCol: 'y'}, inplace=True)\n",
    "\n",
    "    #define prophet model\n",
    "    m = Prophet(\n",
    "                growth='linear',\n",
    "                seasonality_mode='additive',\n",
    "                interval_width=0.95,\n",
    "                daily_seasonality=True,\n",
    "                weekly_seasonality=True,\n",
    "                yearly_seasonality=False\n",
    "            )\n",
    "    #train prophet model\n",
    "    m.fit(temp_df)\n",
    "    future = m.make_future_dataframe(periods=4, freq = \"W\")        \n",
    "    features = m.predict(future)\n",
    "    return pd.merge(df, features, left_on=[dateCol], right_on=['ds'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67de9516-728c-4d91-a521-9b4c9ad78b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error,mean_absolute_error\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "def TrainModelWithProphet(df,end = 44,starting = 8,useProphet = True,dataInicial = pd.Timestamp('1960-01-01'),monetary = \"sumProfit\"):\n",
    "    #trainCols = ['CustomerID', 'WeekID','firstRecentGapBetweenOrders', 'meanOrderProfit','diffMaxMinOrderProfit', 'daysSinceLastOrder']\n",
    "    trainCols = ['CustomerID', 'WeekID', 'sumProfit', 'numberOfUniqueItems','timeSinceLastPurchase', \n",
    "                 'timeSinceFirstPurchase', 'cumSumPurchases',\"numberOfOrders\", \"meanOrderProfit\"]\n",
    "    if useProphet:\n",
    "        df[\"WeekDay\"] = pd.to_datetime(df[\"WeekID\"],unit='W',origin=dataInicial)\n",
    "        trainColsProphet = ['CustomerID', 'WeekID', 'sumProfit', 'numberOfUniqueItems','timeSinceLastPurchase', \n",
    "                     'timeSinceFirstPurchase', 'cumSumPurchases',\"numberOfOrders\", \"meanOrderProfit\",\n",
    "                     'trend','yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper',\n",
    "                     'additive_terms', 'additive_terms_lower', 'additive_terms_upper',\n",
    "                     'daily', 'daily_lower', 'daily_upper', 'weekly', 'weekly_lower',\n",
    "                     'weekly_upper', 'multiplicative_terms', 'multiplicative_terms_lower',\n",
    "                     'multiplicative_terms_upper', 'yhat']\n",
    "    mseDict = {}\n",
    "    #targetCol = [\"meanOrderProfit\"]\n",
    "    targetCol = [\"numberOfOrders\", \"meanOrderProfit\"]\n",
    "    dfResultados = pd.DataFrame()\n",
    "    for target in targetCol:\n",
    "        for i in range(starting,end,1):\n",
    "            if useProphet:\n",
    "                dfSlice = df[df[\"WeekID\"] <= i]\n",
    "                dfSlice = prophet_features(dfSlice,\"WeekDay\",monetary)\n",
    "            else:\n",
    "                dfSlice = df[df[\"WeekID\"] <= i]\n",
    "            \n",
    "            dfTreino = dfSlice[ (dfSlice[\"WeekID\"] == i-4)]\n",
    "            dfValid =  dfSlice[ (dfSlice[\"WeekID\"] == i)]\n",
    "            dfPredict = df[ (df[\"WeekID\"] == i+4)]\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            print(f\"Training with in : {str(i)}\")\n",
    "            X_train_Array = dfTreino[trainCols]\n",
    "            Y_train_Array =  dfValid[target]\n",
    "\n",
    "            print(f\"Using {i+4} to validate\")\n",
    "            X_valid_Array = dfValid[trainCols]\n",
    "            Y_valid_Array = dfPredict[target]\n",
    "            \n",
    "            model = xgb.XGBRegressor()\n",
    "            trainHistory = model.fit(\n",
    "                            X_train_Array,\n",
    "                            Y_train_Array)\n",
    "\n",
    "            pred = model.predict(X_valid_Array)\n",
    "            \n",
    "            \n",
    "            dfResultados['ExpectedML '+str(target)+\" \"+str(i+4)] = list(pred)\n",
    "            dfResultados['Real Expected '+str(target)+\" \"+str(i+4)]  =  Y_valid_Array.values\n",
    "            #mseDict[i] = mean_squared_error(Y_valid_Array.values, pred)\n",
    "            #print(\"Mse \",mseDict[i])\n",
    "            #print(\"MSE Sem o Prophet:\", mean_squared_error(Y_valid_Array.values, pred))\n",
    "            #print(model.feature_importances_)\n",
    "            #print(X_train_Array.columns)\n",
    "            \n",
    "            if useProphet:\n",
    "                modelProphet = xgb.XGBRegressor()\n",
    "                trainHistory = modelProphet.fit(\n",
    "                                dfTreino[trainColsProphet],\n",
    "                                dfValid[target])\n",
    "    \n",
    "                pred = modelProphet.predict(dfValid[trainColsProphet])\n",
    "                #print(\"MSE com o Prophet:\", mean_squared_error(Y_valid_Array.values, pred))\n",
    "                #print(dfTreino[trainColsProphet].columns)\n",
    "                #print(modelProphet.feature_importances_)\n",
    "\n",
    "\n",
    "                \n",
    "                dfResultados['ExpectedMLP '+str(target)+\" \"+str(i+4)] = list(pred)\n",
    "\n",
    "    return dfResultados\n",
    "\n",
    "\n",
    "#dfResultados = TrainModelWithProphet(df,dataInicial = dataInicial,starting = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563db2fb-5d70-4bd7-8591-5b071fc1a96b",
   "metadata": {},
   "source": [
    "### Cálculo de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbda9dbe-607f-4a98-81f8-700ff469e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "\n",
    "def intervaloConfiancaErros(Y,Predicted):\n",
    "    errors = abs(Y - Predicted)\n",
    "    # Nível de confiança\n",
    "    confidence_level = 0.95\n",
    "    #print(errors.mean())\n",
    "    # Calcular o intervalo de confiança para a média dos erros de previsão\n",
    "    ci = sms.DescrStatsW(errors).tconfint_mean(alpha=1-confidence_level)\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b357dc61-814b-44b7-82f4-edd8be6ee395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score, max_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Calcula o RMSE manualmente \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def retornarMétricas(TrueValues, Predicted, metricList=None, dataName=\"Dataset\"):\n",
    "    if metricList is None:\n",
    "        metricList = [mean_absolute_error, root_mean_squared_error, intervaloConfiancaErros]  \n",
    "    res = {}\n",
    "    for metric in metricList:\n",
    "        res[metric.__name__] = metric(TrueValues, Predicted)\n",
    "\n",
    "    return res\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a2529f2-2156-4256-be48-92a9a25ce4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error,mean_squared_error,mean_absolute_error,r2_score,max_error\n",
    "\n",
    "\n",
    "def retornarMétricas(TrueValues,Predicted, metricList = None,dataName = \"Dataset\"):\n",
    "    if metricList == None:\n",
    "        metricList = [mean_squared_error,mean_absolute_error,r2_score,max_error,root_mean_squared_error,intervaloConfiancaErros]\n",
    "    res = {}\n",
    "    for metric in metricList:\n",
    "        res[metric.__name__] = metric(TrueValues,Predicted)\n",
    "\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "567b6891-8b71-4010-99b1-45c89f19c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionarErroSoluções(dfResultados,Xt,Yt,Xm,Ym,dadosML,indexOfComparisson):\n",
    "    dfResultados[\"Erro Bauer Transaction\"] = abs(Xt['Prediction '+str(indexOfComparisson)] - Yt['True '+str(indexOfComparisson)])\n",
    "    dfResultados[\"Erro Solução Transaction\"] = abs(dfResultados['ExpectedML numberOfOrders '+str(indexOfComparisson)] - dfResultados['Real Expected numberOfOrders '+str(indexOfComparisson)])\n",
    "    dfResultados[\"Erro Solução Transaction Prophet\"] = abs(dfResultados['ExpectedMLP numberOfOrders '+str(indexOfComparisson)] - dfResultados['Real Expected numberOfOrders '+str(indexOfComparisson)])\n",
    "    \n",
    "    dfResultados[\"Erro Bauer Monetary\"] = abs(Xm['Prediction '+str(indexOfComparisson)] - Ym['True '+str(indexOfComparisson)])\n",
    "    dfResultados[\"Erro Solução Monetary\"] = abs(dfResultados['ExpectedML meanOrderProfit '+str(indexOfComparisson)] - dfResultados['Real Expected meanOrderProfit '+str(indexOfComparisson)])\n",
    "    dfResultados[\"Erro Solução Monetary Prophet\"] = abs(dfResultados['ExpectedMLP meanOrderProfit '+str(indexOfComparisson)] - dfResultados['Real Expected numberOfOrders '+str(indexOfComparisson)])\n",
    "    \n",
    "    \n",
    "    dfResultados[\"Erro ENIAC Transaction\"] = abs(dadosML['ExpectedMLT '+str(indexOfComparisson)] - dadosML['Real Expected Transactions'+str(indexOfComparisson)] )\n",
    "    dfResultados[\"Erro ENIAC Monetary\"] = abs(dadosML['ExpectedMLM '+str(indexOfComparisson)] - dadosML['Real Expected Monetary'+str(indexOfComparisson)] )\n",
    "    \n",
    "    dfResultados[\"Erro BGF\"] = abs(dadosML['ExpectedBGF '+str(indexOfComparisson)] - dadosML['Real Expected Transactions'+str(indexOfComparisson)] )\n",
    "    dfResultados[\"Erro Pareto\"] = abs(dadosML['ExpectedPareto '+str(indexOfComparisson)] - dadosML['Real Expected Transactions'+str(indexOfComparisson)] )\n",
    "    dfResultados[\"Erro GammaGamma\"] = abs(dadosML['ExpectedGGF '+str(indexOfComparisson)] - dadosML['Real Expected Monetary'+str(indexOfComparisson)] )\n",
    "\n",
    "    dfResultados[\"Predicao Final Bauer\"] = Xt['Prediction '+str(indexOfComparisson)]\n",
    "    dfResultados[\"Predicao Final Solução\"]= dfResultados['ExpectedML numberOfOrders '+str(indexOfComparisson)]\n",
    "    dfResultados[\"Predicao Final Solução + Prophet\"]= dfResultados['ExpectedMLP numberOfOrders '+str(indexOfComparisson)]\n",
    "    dfResultados[\"Predicao Final ENIAC\"] = dadosML['ExpectedMLT '+str(indexOfComparisson)]+1\n",
    "    dfResultados[\"Predicao Final BGF\"] = dadosML['ExpectedBGF '+str(indexOfComparisson)]+1\n",
    "    dfResultados[\"Predicao Final Pareto\"] = dadosML['ExpectedPareto '+str(indexOfComparisson)]+1\n",
    "    dfResultados[\"Predicao Final Real\"] = dfResultados['Real Expected numberOfOrders '+str(indexOfComparisson)]\n",
    "    #dfResultados[\"Predicao Final Real 2\"] = dadosML['Real Expected'+str(72)]+1\n",
    "    return dfResultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21066548-ea59-4e94-8610-e96a921da24f",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82493a3f-9e57-4bae-bd45-0572048e6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_clv(actual, predicted, bins, title = \"\"):\n",
    "    print(f\"Average absolute error: {mean_absolute_error(actual, predicted)}\")\n",
    "    print(f\"Average Percentage error: {mean_absolute_percentage_error(actual, predicted)}\")\n",
    "\n",
    "    #Evaluate numeric\n",
    "    ypbot = np.percentile(actual, 1)\n",
    "    yptop = np.percentile(actual, 99)\n",
    "    ypad = 0.2*(yptop - ypbot)\n",
    "    ymin = ypbot - ypad\n",
    "    ymax = yptop + ypad\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    #ax = sns.scatterplot(predicted, actual)\n",
    "    ax = sns.scatterplot(x=predicted,y=actual)\n",
    "\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Atual')\n",
    "    plt.title('Previsto vs Atual '+title)\n",
    "    ax.set_xlim([ymin, ymax])\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "    plt.show()\n",
    "\n",
    "    #Evaluate Bins\n",
    "    est = KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='kmeans')\n",
    "    est.fit(np.array(actual).reshape(-1, 1))\n",
    "    actual_bin = est.transform(np.array(actual).reshape(-1, 1)).ravel()\n",
    "    predicted_bin = est.transform(np.array(predicted).reshape(-1, 1)).ravel()\n",
    "\n",
    "    cm = confusion_matrix(actual_bin, predicted_bin, normalize='true')\n",
    "    df_cm = pd.DataFrame(cm, index = range(1, bins+1),\n",
    "                      columns = range(1, bins+1))\n",
    "    plt.figure(figsize = (20,10))\n",
    "    sns.heatmap(df_cm, annot=True)\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Atual')\n",
    "    plt.title('Heatmap Previsto vs Atual '+title)\n",
    "\n",
    "    # fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "    plt.show()\n",
    "    print(f'F1 score: {f1_score(actual_bin, predicted_bin, average=\"macro\")}')\n",
    "    print('Samples in each bin: \\n')\n",
    "    print(pd.Series(actual_bin).value_counts())\n",
    "\n",
    "#evaluate_clv(dfResultados['Real Expected72'], dfResultados['ExpectedML 72'], bins=10,title=\"Transações na base CDNOW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6bb12-9e88-4977-a6d0-c6f0bea54478",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90373085-1888-4e97-b1be-f5f1a40a3591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MixedSolution(bauerTrain,bauerTest,weekID,yTrain,yTest):\n",
    "    #trainCols = ['CustomerID', 'WeekID','firstRecentGapBetweenOrders', 'meanOrderProfit','diffMaxMinOrderProfit', 'daysSinceLastOrder']\n",
    "    trainCols = ['CustomerID', 'WeekID', 'sumProfit', 'numberOfUniqueItems','timeSinceLastPurchase', \n",
    "                 'timeSinceFirstPurchase', 'cumSumPurchases',\"numberOfOrders\", \"meanOrderProfit\"]\n",
    "\n",
    "    #targetCol = [\"meanOrderProfit\"]\n",
    "    targetCol = [\"monetary_holdout\", \"frequency_holdout\"]\n",
    "    dfResultados = pd.DataFrame({\"Index\" : bauerTest[\"CustomerID\"].astype(int).unique()})\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "    dfTreino = bauerTrain[ (bauerTrain[\"WeekID\"] == weekID)]\n",
    "    dfValid =  bauerTest[ (bauerTest[\"WeekID\"] == weekID+4)]\n",
    "\n",
    "    for target in targetCol:\n",
    "        print(f\"Training with in : {str(weekID)}\")\n",
    "        X_train_Array = dfTreino[trainCols].set_index(\"CustomerID\")\n",
    "        #Y_train_Array =  dfValid[target]\n",
    "        #return X_train_Array,Y_train_Array\n",
    "        print(f\"Using {weekID+4} to validate\")\n",
    "        X_valid_Array = dfValid[trainCols].set_index(\"CustomerID\")\n",
    "        #Y_valid_Array = dfPredict[target]\n",
    "        model = escolheModeloCustom(X_train_Array,X_valid_Array,yTrain[target],yTest[target],target = target)  \n",
    "        pred = model.predict(X_valid_Array)\n",
    "        \n",
    "        print(f\"Predicting {weekID+8}\")\n",
    "\n",
    "        dfResultados['Expected Mixed '+str(target)+\" \"+str(weekID+8)] = list(pred)\n",
    "\n",
    "    return dfResultados.set_index(\"Index\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e0d4b7-6c09-4084-bb62-f584af9a34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def individualTestProphet(df,weekID,useProphet = False,dataInicial = pd.Timestamp('1960-01-01'),monetary = \"sumProfit\"):\n",
    "    #trainCols = ['CustomerID', 'WeekID','firstRecentGapBetweenOrders', 'meanOrderProfit','diffMaxMinOrderProfit', 'daysSinceLastOrder']\n",
    "    trainCols = ['CustomerID', 'WeekID', 'sumProfit', 'numberOfUniqueItems','timeSinceLastPurchase', \n",
    "                 'timeSinceFirstPurchase', 'cumSumPurchases',\"numberOfOrders\", \"meanOrderProfit\"]\n",
    "    if useProphet:\n",
    "        df[\"WeekDay\"] = pd.to_datetime(df[\"WeekID\"],unit='W',origin=dataInicial)\n",
    "        trainColsProphet = ['CustomerID', 'WeekID', 'sumProfit', 'numberOfUniqueItems','timeSinceLastPurchase', \n",
    "                     'timeSinceFirstPurchase', 'cumSumPurchases',\"numberOfOrders\", \"meanOrderProfit\",\n",
    "                     'trend','yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper',\n",
    "                     'additive_terms', 'additive_terms_lower', 'additive_terms_upper',\n",
    "                     'daily', 'daily_lower', 'daily_upper', 'weekly', 'weekly_lower',\n",
    "                     'weekly_upper', 'multiplicative_terms', 'multiplicative_terms_lower',\n",
    "                     'multiplicative_terms_upper', 'yhat']\n",
    "    #targetCol = [\"meanOrderProfit\"]\n",
    "    targetCol = [\"numberOfOrders\", \"meanOrderProfit\"]\n",
    "    dfResultados = pd.DataFrame({\"Index\" : dfBauer[\"CustomerID\"].astype(int).unique()})\n",
    "\n",
    "\n",
    "    if useProphet:\n",
    "        dfSlice = df[df[\"WeekID\"] <= weekID+4]\n",
    "        dfSlice = prophet_features(dfSlice,\"WeekDay\",monetary)\n",
    "    else:\n",
    "        dfSlice = df[df[\"WeekID\"] <= weekID+4]\n",
    "    \n",
    "    dfTreino = dfSlice[ (dfSlice[\"WeekID\"] == weekID)]\n",
    "    dfValid =  dfSlice[ (dfSlice[\"WeekID\"] == weekID+4)]\n",
    "    dfPredict = df[ (df[\"WeekID\"] == weekID+8)]       \n",
    "\n",
    "    for target in targetCol:\n",
    "        print(f\"Training with in : {str(weekID)}\")\n",
    "        X_train_Array = dfTreino[trainCols].set_index(\"CustomerID\")\n",
    "        Y_train_Array =  dfValid[target]\n",
    "        #return X_train_Array,Y_train_Array\n",
    "        print(f\"Using {weekID+4} to validate\")\n",
    "        X_valid_Array = dfValid[trainCols].set_index(\"CustomerID\")\n",
    "        Y_valid_Array = dfPredict[target]\n",
    "        model = escolheModeloCustom(X_train_Array,X_valid_Array,Y_train_Array,Y_valid_Array,target = target)  \n",
    "        pred = model.predict(X_valid_Array)\n",
    "        \n",
    "        print(f\"Predicting {weekID+8}\")\n",
    "\n",
    "        dfResultados['ExpectedML '+str(target)+\" \"+str(weekID+8)] = list(pred)\n",
    "        dfResultados['Real Expected Bauer '+str(target)+\" \"+str(weekID+8)]  =  Y_valid_Array.values\n",
    "        \n",
    "        if useProphet:\n",
    "            modelProphet =  escolheModeloCustom(dfTreino[trainColsProphet],\n",
    "                                                dfValid[trainColsProphet],Y_train_Array,Y_valid_Array,target = target)\n",
    "            pred = modelProphet.predict(dfValid[trainColsProphet])\n",
    "            #print(\"MSE com o Prophet:\", mean_squared_error(Y_valid_Array.values, pred))\n",
    "            #print(dfTreino[trainColsProphet].columns)\n",
    "            #print(modelProphet.feature_importances_)\n",
    "\n",
    "\n",
    "            \n",
    "            dfResultados['ExpectedMLP '+str(target)+\" \"+str(weekID+8)] = list(pred)\n",
    "\n",
    "    return dfResultados.set_index(\"Index\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b21d0a7-2941-4365-a42b-0cd4af132a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "def stackingModel(X_train,X_val,Y_Train,Y_val):\n",
    "    base_models = [\n",
    "    ('Enet', ElasticNet()),\n",
    "    ('rf', RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42)),\n",
    "    ('ridge', Ridge(alpha=10, random_state=42)),\n",
    "    ('xgb', XGBRegressor(objective='reg:squarederror', n_estimators=300, max_depth=5, learning_rate=0.1, random_state=42)),\n",
    "    ('lgbm', LGBMRegressor(n_estimators=300, max_depth=5, learning_rate=0.1, random_state=42,objective='regression',verbose=-1)),\n",
    "    ('catboost', CatBoostRegressor(n_estimators=300, max_depth=5, learning_rate=0.1, random_state=42, verbose=0))\n",
    "]\n",
    "    stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=Ridge())\n",
    "    stacking_regressor.fit(X_train, Y_Train)\n",
    "    return stacking_regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29279d2a-d8f1-41a4-85c1-0e4fe8cb11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separaPorcentagem(dataset,coluna,porcentagem = 0.5):\n",
    "    limiar = dataset[coluna].sort_values().iloc[int(dataset.shape[0] * porcentagem)]\n",
    "    return  np.where(dataset[coluna] > limiar,1,0)\n",
    "\n",
    "def fill_column(dataframe: pd.DataFrame, list: list, column: str):\n",
    "    dict_from_list = dict(enumerate(list)) # create enumertable object from list and create dict\n",
    "\n",
    "    dataFrame_asDict = dataframe.to_dict() # Get DataFrame as Dict\n",
    "    dataFrame_asDict[column] = dict_from_list # Assign specific column\n",
    "\n",
    "    return pd.DataFrame.from_dict(dataFrame_asDict, orient='index').T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd34edff-b3ca-4e18-9215-898c785fcefb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_palette(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrocket\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(starting,end,\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     dfResultados[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErro \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[43mXt\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m-\u001b[39m Yt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)])\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#dfResultados[\"Erro \"+str(i)] = abs(dfResultados['ExpectedML '+str(i)] - dfResultados['Real Expected'+str(i)])\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErro \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "starting = 20\n",
    "end = 36\n",
    "\n",
    "labels = []\n",
    "fig, ax = plt.subplots()\n",
    "# Definindo a paleta de cores\n",
    "results = {}\n",
    "sns.set_palette(\"rocket\")\n",
    "\n",
    "for i in range(starting,end,4):\n",
    "    dfResultados[\"Erro \"+str(i)] = abs(Xt['Prediction '+str(i)] - Yt['True '+str(i)])\n",
    "    #dfResultados[\"Erro \"+str(i)] = abs(dfResultados['ExpectedML '+str(i)] - dfResultados['Real Expected'+str(i)])\n",
    "    labels.append(\"Erro \"+str(i))\n",
    "\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(dfResultados[labels]))\n",
    "\n",
    "plt.title(\"Erro calculado na Base CDNOW nas Transações do Modelo Bauer\")\n",
    "plt.ylabel(\"Erro\")\n",
    "plt.xlabel(\"Período\")\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3112bb89-cbe0-4c84-b0ae-98c538d17455",
   "metadata": {},
   "source": [
    "### CDNOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14aef0c7-9d64-435c-9e66-e52171c34304",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"CDNOW\"\n",
    "Xt =  pd.read_csv(\"Arquivos/Prediction CDNOW numberOfOrders.csv\")\n",
    "Yt = pd.read_csv(\"Arquivos/True CDNOW numberOfOrders.csv\")\n",
    "\n",
    "Xm = pd.read_csv(\"Arquivos/Prediction CDNOW meanOrderProfit.csv\")\n",
    "Ym = pd.read_csv(\"Arquivos/True CDNOW meanOrderProfit.csv\")\n",
    "\n",
    "dfBauer = pd.read_csv(\"Arquivos/CDNOW_FINAL.csv\")\n",
    "\n",
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_CDNOW Clean.csv\")\n",
    "dfUnprocesses['OrderDate'] = pd.to_datetime(dfUnprocesses['OrderDate'])\n",
    "dfUnprocesses.dropna(inplace = True)\n",
    "dfUnprocesses = dfUnprocesses[dfUnprocesses[\"CustomerID\"].isin(dfBauer.CustomerID.astype(int).values)]\n",
    "\n",
    "indexOfComparisson = 72\n",
    "targetTimeLength = 4 \n",
    "seqInLength = 2*targetTimeLength\n",
    "seqOutLength = targetTimeLength\n",
    "training_start,training_end,holdout_start,holdout_end = getBauerDatasetSplitTimes(dfBauer.reset_index().WeekID,seqOutLength)\n",
    "targetTimeLength = holdout_end - holdout_start\n",
    "numSeqFeat = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"]).size\n",
    "seqFeatVec = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"])\n",
    "training_start = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdea53c0-6e16-485c-8937-830558b6cb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDNOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minímo de Transações</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moda de transações</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Máximo de transações</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Média Transações</th>\n",
       "      <td>3.253205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Periodos (Semanas)</th>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Transações</th>\n",
       "      <td>1015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usuários</th>\n",
       "      <td>312.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            CDNOW\n",
       "Minímo de Transações     1.000000\n",
       "Moda de transações       2.000000\n",
       "Máximo de transações     9.000000\n",
       "Média Transações         3.253205\n",
       "Periodos (Semanas)      78.000000\n",
       "Total Transações      1015.000000\n",
       "Usuários               312.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks = dfBauer.WeekID.nunique()\n",
    "customers = dfBauer.CustomerID.nunique()\n",
    "numTransactions = dfUnprocesses.CustomerID.size\n",
    "userTransactions = dfUnprocesses.groupby(\"CustomerID\").ItemProfit.count()\n",
    "mediaTransacoes = userTransactions.mean()\n",
    "modaTransacao = userTransactions.mode().iloc[0]\n",
    "minTransaction = userTransactions.min()\n",
    "maxTransaction = userTransactions.max()\n",
    "\n",
    "metricas = { \"CDNOW\" : {\n",
    "    \"Periodos (Semanas)\" : weeks,\n",
    "    \"Usuários\" : customers,\n",
    "    \"Total Transações\" : numTransactions,\n",
    "    \"Média Transações\" : mediaTransacoes,\n",
    "    \"Minímo de Transações\" : minTransaction,\n",
    "    \"Máximo de transações\" : maxTransaction,\n",
    "    \"Moda de transações\" : modaTransacao\n",
    "}}\n",
    "metricas\n",
    "\n",
    "\n",
    "pd.DataFrame(metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c4337-04ea-4580-aa32-30f82638af61",
   "metadata": {},
   "source": [
    "### Shopping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "240f49de-1d00-49f8-a0fc-6cb462a2c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"Shopping\"\n",
    "\n",
    "Xt =  pd.read_csv(\"Arquivos/Prediction ShoppingData numberOfOrders.csv\")\n",
    "Yt = pd.read_csv(\"Arquivos/True ShoppingData numberOfOrders.csv\")\n",
    "\n",
    "\n",
    "Xm = pd.read_csv(\"Arquivos/Prediction ShoppingData meanOrderProfit.csv\")\n",
    "Ym = pd.read_csv(\"Arquivos/True ShoppingData meanOrderProfit.csv\")\n",
    "\n",
    "\n",
    "dfBauer = pd.read_csv(\"Arquivos/Shopping_FINAL.csv\")\n",
    "\n",
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_Shopping Clean.csv\")\n",
    "dfUnprocesses['OrderDate'] = pd.to_datetime(dfUnprocesses['OrderDate'])\n",
    "dfUnprocesses['OrderDate']  = dfUnprocesses['OrderDate'].dt.tz_convert(None)\n",
    "dfUnprocesses.dropna(inplace = True)\n",
    "dfUnprocesses = dfUnprocesses[dfUnprocesses[\"CustomerID\"].isin(dfBauer.CustomerID.values)]\n",
    "\n",
    "\n",
    "training_start,training_end,holdout_start,holdout_end = 8,12,16,17\n",
    "indexOfComparisson = 20\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a6885e6-49f9-45c4-ade8-bfca391d7933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shopping Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Minímo de Transações</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moda de transações</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Máximo de transações</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Média Transações</th>\n",
       "      <td>1.198232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Periodos (Semanas)</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Transações</th>\n",
       "      <td>62882.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usuários</th>\n",
       "      <td>52479.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Shopping Data\n",
       "Minímo de Transações       1.000000\n",
       "Moda de transações         1.000000\n",
       "Máximo de transações       6.000000\n",
       "Média Transações           1.198232\n",
       "Periodos (Semanas)        22.000000\n",
       "Total Transações       62882.000000\n",
       "Usuários               52479.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks = dfBauer.WeekID.nunique()\n",
    "customers = dfBauer.CustomerID.nunique()\n",
    "numTransactions = dfUnprocesses.CustomerID.size\n",
    "userTransactions = dfUnprocesses.groupby(\"CustomerID\").ItemProfit.count()\n",
    "mediaTransacoes = userTransactions.mean()\n",
    "modaTransacao = userTransactions.mode().iloc[0]\n",
    "minTransaction = userTransactions.min()\n",
    "maxTransaction = userTransactions.max()\n",
    "\n",
    "metricas = { \"Shopping Data\" : {\n",
    "    \"Periodos (Semanas)\" : weeks,\n",
    "    \"Usuários\" : customers,\n",
    "    \"Total Transações\" : numTransactions,\n",
    "    \"Média Transações\" : mediaTransacoes,\n",
    "    \"Minímo de Transações\" : minTransaction,\n",
    "    \"Máximo de transações\" : maxTransaction,\n",
    "    \"Moda de transações\" : modaTransacao\n",
    "}}\n",
    "metricas\n",
    "\n",
    "\n",
    "pd.DataFrame(metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d4ef6-4661-4489-9de2-aa7397959b85",
   "metadata": {},
   "source": [
    "### Bank Data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096b96b-6ca7-4aff-aa34-66a3d99b907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"Bank Data 1\"\n",
    "\n",
    "Xt =  pd.read_csv(\"Arquivos/Prediction BANKData1 numberOfOrders.csv\")\n",
    "Yt = pd.read_csv(\"Arquivos/True BANKData1 numberOfOrders.csv\")\n",
    "\n",
    "\n",
    "Xm = pd.read_csv(\"Arquivos/Prediction BANKData1 meanOrderProfit.csv\")\n",
    "Ym = pd.read_csv(\"Arquivos/True BANKData1 meanOrderProfit.csv\")\n",
    "\n",
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_Bank CleanIDS.csv\")\n",
    "dfUnprocesses['OrderDate'] = pd.to_datetime(dfUnprocesses['OrderDate'])\n",
    "\n",
    "dfUnprocesses.dropna(inplace = True)\n",
    "\n",
    "dfBauer = pd.read_csv(\"Arquivos/BANK_DATA_FINAL.csv\")\n",
    "\n",
    "dfUnprocesses = dfUnprocesses[dfUnprocesses[\"CustomerID\"].isin(dfBauer.CustomerID.values)]\n",
    "dfUnprocesses = dfUnprocesses.drop([\"Unnamed: 0.1\",\"Unnamed: 0\"],axis =1)\n",
    "dfBauer = dfBauer.drop([\"Unnamed: 0\"],axis =1)\n",
    "\n",
    "\n",
    "training_start,training_end,holdout_start,holdout_end = getBauerDatasetSplitTimes(dfBauer.reset_index().WeekID,seqOutLength)\n",
    "training_start = 12\n",
    "indexOfComparisson = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7963e1-d886-48bc-892d-6780a8b70157",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = dfBauer.WeekID.nunique()\n",
    "customers = dfBauer.CustomerID.nunique()\n",
    "numTransactions = dfUnprocesses.CustomerID.size\n",
    "userTransactions = dfUnprocesses.groupby(\"CustomerID\").ItemProfit.count()\n",
    "mediaTransacoes = userTransactions.mean()\n",
    "modaTransacao = userTransactions.mode().iloc[0]\n",
    "minTransaction = userTransactions.min()\n",
    "maxTransaction = userTransactions.max()\n",
    "\n",
    "metricas = { \"Bank Data 1\" : {\n",
    "    \"Periodos (Semanas)\" : weeks,\n",
    "    \"Usuários\" : customers,\n",
    "    \"Total Transações\" : numTransactions,\n",
    "    \"Média Transações\" : mediaTransacoes,\n",
    "    \"Minímo de Transações\" : minTransaction,\n",
    "    \"Máximo de transações\" : maxTransaction,\n",
    "    \"Moda de transações\" : modaTransacao\n",
    "}}\n",
    "metricas\n",
    "\n",
    "\n",
    "pd.DataFrame(metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e4e87-41a4-4c19-a649-2fc3be0d29df",
   "metadata": {},
   "source": [
    "### Bank Data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d1d65-191c-4bd7-b82f-7a150584c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_CzechClean.csv\")\n",
    "dfUnprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3767b-b9a8-401c-9c13-6421417c134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"Bank Data 2\"\n",
    "#df = pd.read_csv(\"../Dados/Modelos Bauer/CzechBank.csv\")\n",
    "\n",
    "Xt =  pd.read_csv(\"Arquivos/Prediction BANKData2 numberOfOrders.csv\")\n",
    "Yt = pd.read_csv(\"Arquivos/True BANKData2 numberOfOrders.csv\")\n",
    "\n",
    "\n",
    "Xm = pd.read_csv(\"Arquivos/Prediction BANKData2 meanOrderProfit.csv\")\n",
    "Ym = pd.read_csv(\"Arquivos/True BANKData2 meanOrderProfit.csv\")\n",
    "\n",
    "dfBauer = pd.read_csv(\"Arquivos/CzechBank_FINAL.csv\")\n",
    "\n",
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_CzechClean.csv\")\n",
    "\n",
    "training_start,training_end,holdout_start,holdout_end = getBauerDatasetSplitTimes(dfBauer.reset_index().WeekID,seqOutLength)\n",
    "\n",
    "dfUnprocesses = dfUnprocesses[dfUnprocesses[\"CustomerID\"].isin(dfBauer.CustomerID.values)]\n",
    "\n",
    "targetTimeLength = holdout_end - holdout_start\n",
    "numSeqFeat = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"]).size\n",
    "seqFeatVec = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"])\n",
    "training_start = holdout_start - 8\n",
    "holdout_start = 308\n",
    "indexOfComparisson = 308\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e0e61-2d65-483c-ada1-b4cc925a65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = dfBauer.WeekID.nunique()\n",
    "customers = dfBauer.CustomerID.nunique()\n",
    "numTransactions = dfUnprocesses.CustomerID.size\n",
    "userTransactions = dfUnprocesses.groupby(\"CustomerID\").ItemProfit.count()\n",
    "mediaTransacoes = userTransactions.mean()\n",
    "modaTransacao = userTransactions.mode().iloc[0]\n",
    "minTransaction = userTransactions.min()\n",
    "maxTransaction = userTransactions.max()\n",
    "\n",
    "metricas = { \"Bank Data 2\" : {\n",
    "    \"Periodos (Semanas)\" : weeks,\n",
    "    \"Usuários\" : customers,\n",
    "    \"Total Transações\" : numTransactions,\n",
    "    \"Média Transações\" : mediaTransacoes,\n",
    "    \"Minímo de Transações\" : minTransaction,\n",
    "    \"Máximo de transações\" : maxTransaction,\n",
    "    \"Moda de transações\" : modaTransacao\n",
    "}}\n",
    "metricas\n",
    "\n",
    "\n",
    "pd.DataFrame(metricas).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef25553-f563-4ea0-9113-4cb914443adb",
   "metadata": {},
   "source": [
    "### Olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836c45d-6d98-412b-aef7-f27f1a90820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_Olist Clean.csv\")\n",
    "dfUnprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c0066-040d-44d0-96a1-10d924590932",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"Olist\"\n",
    "\n",
    "Xt =  pd.read_csv(\"Arquivos/Prediction Olist numberOfOrders.csv\")\n",
    "Yt = pd.read_csv(\"Arquivos/True Olist numberOfOrders.csv\")\n",
    "\n",
    "\n",
    "Xm = pd.read_csv(\"Arquivos/Prediction Olist meanOrderProfit.csv\")\n",
    "Ym = pd.read_csv(\"Arquivos/True Olist meanOrderProfit.csv\")\n",
    "\n",
    "dfBauer = pd.read_csv(\"Arquivos/Olist_FINAL.csv\")\n",
    "\n",
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_Olist Clean.csv\")\n",
    "\n",
    "\n",
    "custData = dfUnprocesses.groupby([\"customer_unique_id\"]).count()\n",
    "repeatTransactionsDataset = dfUnprocesses[dfUnprocesses.customer_unique_id.isin(custData[custData.WeekID > 2].index.values)]\n",
    "repeatTransactionsDataset[\"CustomerID\"] = repeatTransactionsDataset.customer_unique_id.astype('category').cat.codes\n",
    "repeatTransactionsDataset[\"CustomerID\"] = repeatTransactionsDataset.CustomerID.astype(int)\n",
    "repeatTransactionsDataset['OrderDate'] = pd.to_datetime(repeatTransactionsDataset['OrderDate'])\n",
    "repeatTransactionsDataset\n",
    "\n",
    "dfUnprocesses = repeatTransactionsDataset\n",
    "dfUnprocesses = dfUnprocesses[dfUnprocesses[\"CustomerID\"].isin(dfBauer.CustomerID.values)]\n",
    "\n",
    "\n",
    "training_start,training_end,holdout_start,holdout_end = 50,90,91,95\n",
    "targetTimeLength = holdout_end - holdout_start\n",
    "numSeqFeat = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"]).size\n",
    "seqFeatVec = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"])\n",
    "start = training_end - 4\n",
    "end = holdout_end\n",
    "indexOfComparisson = 94\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c105ba-edac-4fec-b963-6d0f04b7d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = dfBauer.WeekID.nunique()\n",
    "customers = dfBauer.CustomerID.nunique()\n",
    "numTransactions = dfUnprocesses.CustomerID.size\n",
    "userTransactions = dfUnprocesses.groupby(\"CustomerID\").ItemProfit.count()\n",
    "mediaTransacoes = userTransactions.mean()\n",
    "modaTransacao = userTransactions.mode().iloc[0]\n",
    "minTransaction = userTransactions.min()\n",
    "maxTransaction = userTransactions.max()\n",
    "\n",
    "metricas = { \"Olist\" : {\n",
    "    \"Periodos (Semanas)\" : weeks,\n",
    "    \"Usuários\" : customers,\n",
    "    \"Total Transações\" : numTransactions,\n",
    "    \"Média Transações\" : mediaTransacoes,\n",
    "    \"Minímo de Transações\" : minTransaction,\n",
    "    \"Máximo de transações\" : maxTransaction,\n",
    "    \"Moda de transações\" : modaTransacao\n",
    "}}\n",
    "metricas\n",
    "\n",
    "\n",
    "pd.DataFrame(metricas).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e19472-83cf-4c7c-b8da-f17c43705c5f",
   "metadata": {},
   "source": [
    "### Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6f175-d7a6-4477-b8a9-9b8d81634a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"Real\"\n",
    "dfBauer = pd.read_csv(\"Arquivos/Real_FINAL.csv\")\n",
    "targetTimeLength = 4 \n",
    "seqInLength = 2*targetTimeLength\n",
    "seqOutLength = targetTimeLength\n",
    "training_start,training_end,holdout_start,holdout_end = getBauerDatasetSplitTimes(dfBauer.reset_index().WeekID,seqOutLength)\n",
    "targetTimeLength = holdout_end - holdout_start\n",
    "numSeqFeat = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"]).size\n",
    "seqFeatVec = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"])\n",
    "dfUnprocesses = pd.read_csv(\"Arquivos/customerOrderDT_Real Clean.csv\")\n",
    "dfUnprocesses['OrderDate'] = pd.to_datetime(dfUnprocesses['OrderDate'])\n",
    "\n",
    "dfUnprocesses = dfUnprocesses[dfUnprocesses[\"CustomerID\"].isin(dfBauer.CustomerID.values)]\n",
    "\n",
    "indexOfComparisson = 14\n",
    "\n",
    "training_start = 2\n",
    "holdout_start = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849a7db-4985-4db5-bbed-53e56fdc98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = dfBauer.WeekID.nunique()\n",
    "customers = dfBauer.CustomerID.nunique()\n",
    "numTransactions = dfUnprocesses.CustomerID.size\n",
    "userTransactions = dfUnprocesses.groupby(\"CustomerID\").ItemProfit.count()\n",
    "mediaTransacoes = userTransactions.mean()\n",
    "modaTransacao = userTransactions.mode().iloc[0]\n",
    "minTransaction = userTransactions.min()\n",
    "maxTransaction = userTransactions.max()\n",
    "\n",
    "metricas = { \"Real\" : {\n",
    "    \"Periodos (Semanas)\" : weeks,\n",
    "    \"Usuários\" : customers,\n",
    "    \"Total Transações\" : numTransactions,\n",
    "    \"Média Transações\" : mediaTransacoes,\n",
    "    \"Minímo de Transações\" : minTransaction,\n",
    "    \"Máximo de transações\" : maxTransaction,\n",
    "    \"Moda de transações\" : modaTransacao\n",
    "}}\n",
    "metricas\n",
    "\n",
    "\n",
    "pd.DataFrame(metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47140f3-108f-4fd4-b8ab-02311721463f",
   "metadata": {},
   "source": [
    "### Solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02add86a-d0ee-41c5-8716-08c09ba41415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 12 16\n",
      "Training with in : 8\n",
      "Using 12 to validate\n",
      "Predicting 16\n",
      "Training with in : 8\n",
      "Using 12 to validate\n",
      "Predicting 16\n",
      "12 16 20\n",
      "Training with in : 12\n",
      "Using 16 to validate\n",
      "Predicting 20\n",
      "Training with in : 12\n",
      "Using 16 to validate\n",
      "Predicting 20\n",
      "8 12 16\n",
      "Periodo 8 de 16\n",
      "\n",
      "\n",
      "<lifetimes.ParetoNBDFitter: fitted with 8257 subjects, alpha: 26.42, beta: 0.00, r: 1.12, s: 0.00>\n",
      "LassoCV  mse: 0.1655 \n",
      "\n",
      "ElasticNet  mse: 0.2248 \n",
      "\n",
      "RandomForestRegressor  mse: 0.1578 \n",
      "\n",
      "GradientBoostingRegressor  mse: 0.1578 \n",
      "\n",
      "HistGradientBoostingRegressor  mse: 0.1566 \n",
      "\n",
      "XGBRegressor  mse: 0.1579 \n",
      "\n",
      "LGBMRegressor  mse: 0.1562 \n",
      "\n",
      "LassoCV  mse: 63.3228 \n",
      "\n",
      "ElasticNet  mse: 63.9183 \n",
      "\n",
      "RandomForestRegressor  mse: 61.0834 \n",
      "\n",
      "GradientBoostingRegressor  mse: 60.8468 \n",
      "\n",
      "HistGradientBoostingRegressor  mse: 61.0340 \n",
      "\n",
      "XGBRegressor  mse: 61.0076 \n",
      "\n",
      "LGBMRegressor  mse: 60.9999 \n",
      "\n",
      "12 16 20\n",
      "Periodo 12 de 16\n",
      "\n",
      "\n",
      "<lifetimes.ParetoNBDFitter: fitted with 22622 subjects, alpha: 37.47, beta: 0.00, r: 1.19, s: 0.00>\n",
      "LassoCV  mse: 0.0741 \n",
      "\n",
      "ElasticNet  mse: 0.1512 \n",
      "\n",
      "RandomForestRegressor  mse: 0.0671 \n",
      "\n",
      "GradientBoostingRegressor  mse: 0.0653 \n",
      "\n",
      "HistGradientBoostingRegressor  mse: 0.0656 \n",
      "\n",
      "XGBRegressor  mse: 0.0690 \n",
      "\n",
      "LGBMRegressor  mse: 0.0661 \n",
      "\n",
      "LassoCV  mse: 30.5146 \n",
      "\n",
      "ElasticNet  mse: 31.5845 \n",
      "\n",
      "RandomForestRegressor  mse: 27.2468 \n",
      "\n",
      "GradientBoostingRegressor  mse: 27.1390 \n",
      "\n",
      "HistGradientBoostingRegressor  mse: 27.2785 \n",
      "\n",
      "XGBRegressor  mse: 27.3559 \n",
      "\n",
      "LGBMRegressor  mse: 27.1306 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "#def testeStacking(\n",
    "bauerTrainCols =  ['CustomerID', 'WeekID', 'sumProfit', 'numberOfUniqueItems','timeSinceLastPurchase', 'timeSinceFirstPurchase', 'cumSumPurchases',\"numberOfOrders\", \"meanOrderProfit\"]\n",
    "df = dfUnprocesses\n",
    "dfBauer = dfBauer\n",
    "minTraining = training_start #Qual é o periodo mínimo que será usado para treino\n",
    "maxTraining = holdout_start #Qual será o último período que será usado para o treino\n",
    "intervalosPredicao = 4 #Define quantos períodos serão os intervalos de predição\n",
    "cID = \"CustomerID\" #Nome da coluna contendo o ID dos clientes\n",
    "cDate = \"OrderDate\"#Nome da coluna onde contém a data das compras\n",
    "cMonetary = 'ItemProfit' #Nome da coluna onde contém a média dos valores monetários\n",
    "frequencia = \"W\"\n",
    "calculateTransactions = True\n",
    "calculateMonetary = True\n",
    "calculateENIAC = True\n",
    "penalizer = 0.01\n",
    "bauerModel = True\n",
    "#segregateCols = [\"numberOfOrders\",\"sumProfit\"]\n",
    "segregateCols = [\"frequency\",\"recency\",\"monetary_value\"]\n",
    "results = []\n",
    "\n",
    "\n",
    "def executaSBBD():\n",
    "    dfResultados =  summary_data_from_transaction_data(df[df[\"WeekID\"] <= maxTraining], \n",
    "                                                    cID, \n",
    "                                                    cDate, \n",
    "                                                    monetary_value_col = cMonetary,freq = frequencia).reset_index()[[cID]].set_index(cID)\n",
    "    \n",
    "    \n",
    "    for periodo in range(minTraining,maxTraining,intervalosPredicao):\n",
    "        calibrationDate = periodo #8\n",
    "        #Validar com os próximos intervalos.\n",
    "        validationEnd = periodo + intervalosPredicao       #12 \n",
    "        predictDate = periodo + (intervalosPredicao*2)    #16\n",
    "        print(calibrationDate,validationEnd,predictDate)   \n",
    "    \n",
    "    \n",
    "        XTrain = summary_data_from_transaction_data(df[df[\"WeekID\"] <= calibrationDate], \n",
    "                                                   cID, cDate, \n",
    "                                                   monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        Ytrain = summary_data_from_transaction_data(df[df[\"WeekID\"] <= validationEnd], \n",
    "                                                    cID, \n",
    "                                                    cDate, \n",
    "                                                    monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia)\n",
    "    \n",
    "        Ytrain = Ytrain.rename(columns={\"frequency\" : \"frequency_holdout\", \"monetary_value\" : \"monetary_holdout\"})[[\"frequency_holdout\",\"monetary_holdout\"]]\n",
    "    \n",
    "        \n",
    "        XTest = summary_data_from_transaction_data(df[df[\"WeekID\"] <= validationEnd], cID, cDate, monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        YTest = summary_data_from_transaction_data(df[df[\"WeekID\"] <= predictDate], cID, cDate, monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        \n",
    "        YTest = YTest.rename(columns={\"frequency\" : \"frequency_holdout\", \"monetary_value\" : \"monetary_holdout\"})[[\"frequency_holdout\",\"monetary_holdout\"]]\n",
    "        \n",
    "        \n",
    "        #XTrain = pd.merge(XTrain, Ytrain,how='inner',left_index=True, right_index=True)\n",
    "        #XTest = pd.merge(XTest, YTest,how='inner',left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "        XTrain = pd.merge(XTrain, dfBauer[dfBauer[\"WeekID\"] == calibrationDate].set_index(\"CustomerID\"),how='left',left_index=True, right_index=True)\n",
    "        XTest = pd.merge(XTest, dfBauer[dfBauer[\"WeekID\"] == validationEnd].set_index(\"CustomerID\"),how='left',left_index=True, right_index=True)\n",
    "    \n",
    "        YTest =  YTest[YTest.index.isin(XTest.index.values)]\n",
    "        Ytrain =  Ytrain[Ytrain.index.isin(XTrain.index.values)]\n",
    "    \n",
    "        trainingCols = XTrain.columns.values\n",
    "    \n",
    "        if segregateCols != []:\n",
    "            bestColsName = [\"Best \" + sub for sub in segregateCols] \n",
    "            \n",
    "            for col in segregateCols:\n",
    "                XTrain[\"Best \"+col] = separaPorcentagem(XTrain,col)\n",
    "                XTest[\"Best \"+col] = separaPorcentagem(XTest,col)\n",
    "        \n",
    "            XTrain[\"Categories\"] = XTrain[bestColsName].dot(XTrain[bestColsName].columns + ', ').str.rstrip(', ')\n",
    "            XTest[\"Categories\"] = XTest[bestColsName].dot(XTest[bestColsName].columns + ', ').str.rstrip(', ')\n",
    "        bestColsName+= [\"Categories\"]\n",
    "    \n",
    "        if calculateTransactions:\n",
    "            start_time = time.time()\n",
    "            modelML = escolheModeloCustom(XTrain[trainingCols], XTest[trainingCols], Ytrain['frequency_holdout'], YTest['frequency_holdout']#\n",
    "                      ,target = 'frequency_holdout' #Nome da coluna de target, sendo a coluna de valor monetário prevista ou frequência\n",
    "                      , tunning = False #Caso queira fazer o Tunning de hyperparâmetros, deixar como true\n",
    "                     )\n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                \"Period\" : predictDate,\n",
    "                \"Model\": \"Transactions Machine Learning Model\",\n",
    "                \"Training Time (seconds)\": end_time - start_time\n",
    "\n",
    "            })\n",
    "\n",
    "            ## Adicionando os resultados para os modelos de Stacking\n",
    "            XTest['ExpectedMLT '+str(predictDate)] = modelML.predict(XTest[trainingCols])\n",
    "            XTrain['ExpectedMLT '+str(predictDate)] = modelML.predict(XTrain[trainingCols])\n",
    "    \n",
    "            start_time = time.time()\n",
    "            stackModel = stackingModel(XTrain[np.append('ExpectedMLT '+str(predictDate),trainingCols)]\n",
    "                                       , XTest[np.append('ExpectedMLT '+str(predictDate),trainingCols)]\n",
    "                                       , Ytrain['frequency_holdout'], YTest['frequency_holdout'])\n",
    "    \n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                \"Period\" : predictDate,\n",
    "                \"Model\": \"Transactions Stacking Model\",\n",
    "                \"Training Time (seconds)\": end_time - start_time\n",
    "\n",
    "            })\n",
    "            XTest['ExpectedMLT Stacking'+str(predictDate)] = stackModel.predict(XTest[np.append('ExpectedMLT '+str(predictDate),trainingCols)])\n",
    "    \n",
    "            XTest['Real Expected Transactions'+str(predictDate)] = YTest['frequency_holdout']\n",
    "            XTest['ExpectedMLT Separated Transactions'+str(predictDate)] = None\n",
    "\n",
    "            start_time = time.time()\n",
    "            for category in XTest.Categories.unique():\n",
    "                separatedXTrain = XTrain[XTrain[\"Categories\"] == category][trainingCols]\n",
    "                separatedYTrain = Ytrain[Ytrain.index.isin(separatedXTrain.index)]\n",
    "                separatedXTest = XTest[XTest[\"Categories\"] == category][trainingCols]\n",
    "                separatedYTest = YTest[YTest.index.isin(separatedXTest.index)]\n",
    "                if len(separatedXTrain) > 10:\n",
    "                    modelML = escolheModeloCustom(separatedXTrain, separatedXTest, separatedYTrain['frequency_holdout'], separatedYTest['frequency_holdout']#\n",
    "                          ,target = 'frequency_holdout' #Nome da coluna de target, sendo a coluna de valor monetário prevista ou frequência\n",
    "                          , tunning = False #Caso queira fazer o Tunning de hyperparâmetros, deixar como true\n",
    "                         )\n",
    "        \n",
    "                    separatedXTest[\"predictResult\"] = modelML.predict(separatedXTest[trainingCols])\n",
    "    \n",
    "                    XTest['ExpectedMLT Separated Transactions'+str(predictDate)] = XTest['ExpectedMLT Separated Transactions'+str(predictDate)].combine_first(separatedXTest[\"predictResult\"])\n",
    "    \n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                \"Period\" : predictDate,\n",
    "                \"Model\": \"Transactions Separated Model\",\n",
    "                \"Training Time (seconds)\": end_time - start_time\n",
    "\n",
    "            })\n",
    "            #dfResultados[dfResultados['ExpectedML '+str(periodo + (intervalosPredicao*2))] < 0]= 0\n",
    "        if calculateMonetary:\n",
    "            start_time = time.time()\n",
    "            modelML = escolheModeloCustom(XTrain[trainingCols], XTest[trainingCols], Ytrain['monetary_holdout'], YTest['monetary_holdout']#\n",
    "                      ,target = 'monetary_holdout' #Nome da coluna de target, sendo a coluna de valor monetário prevista ou frequência\n",
    "                      , tunning = False #Caso queira fazer o Tunning de hyperparâmetros, deixar como true\n",
    "                     )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                \"Period\" : predictDate,\n",
    "                \"Model\": \"Monetary Machine Learning Model\",\n",
    "                \"Training Time (seconds)\": end_time - start_time\n",
    "\n",
    "            })\n",
    "            XTest['ExpectedMLM '+str(predictDate)] = modelML.predict(XTest[trainingCols])\n",
    "            XTrain['ExpectedMLM '+str(predictDate)] = modelML.predict(XTrain[trainingCols])\n",
    "\n",
    "            start_time = time.time()\n",
    "            stackModel = stackingModel(XTrain[np.append('ExpectedMLM '+str(predictDate),trainingCols)]\n",
    "                               , XTest[np.append('ExpectedMLM '+str(predictDate),trainingCols)]\n",
    "                               , Ytrain['monetary_holdout'], YTest['monetary_holdout'])\n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                \"Period\" : predictDate,\n",
    "                \"Model\": \"Monetary Stacking Model\",\n",
    "                \"Training Time (seconds)\": end_time - start_time\n",
    "\n",
    "            })\n",
    "            XTest['ExpectedMLM Stacking'+str(predictDate)] = stackModel.predict(XTest[np.append('ExpectedMLM '+str(predictDate),trainingCols)])\n",
    "            \n",
    "            XTest['Real Expected Monetary'+str(predictDate)] = YTest['monetary_holdout']\n",
    "            XTest['ExpectedMLT Separated Monetary'+str(predictDate)] = None\n",
    "            \n",
    "            start_time = time.time()\n",
    "            for category in XTest.Categories.unique():\n",
    "                separatedXTrain = XTrain[XTrain[\"Categories\"] == category][trainingCols]\n",
    "                separatedYTrain = Ytrain[Ytrain.index.isin(separatedXTrain.index)]\n",
    "                separatedXTest = XTest[XTest[\"Categories\"] == category][trainingCols]\n",
    "                separatedYTest = YTest[YTest.index.isin(separatedXTest.index)]\n",
    "                if len(separatedXTrain) > 10:\n",
    "                    modelML = escolheModeloCustom(separatedXTrain, separatedXTest, separatedYTrain['monetary_holdout'], separatedYTest['monetary_holdout']#\n",
    "                          ,target = 'monetary_holdout' #Nome da coluna de target, sendo a coluna de valor monetário prevista ou frequência\n",
    "                          , tunning = False #Caso queira fazer o Tunning de hyperparâmetros, deixar como true\n",
    "                         )\n",
    "        \n",
    "                    separatedXTest[\"predictResult\"] = modelML.predict(separatedXTest[trainingCols])\n",
    "                    #XTest['ExpectedMLT Separated Monetary'+str(predictDate)] = pd.concat([XTest['ExpectedMLT Separated Monetary'+str(predictDate)], separatedXTest[\"predictResult\"]],axis = 1)\n",
    "                    XTest['ExpectedMLT Separated Monetary'+str(predictDate)] = XTest['ExpectedMLT Separated Monetary'+str(predictDate)].combine_first(separatedXTest[\"predictResult\"])\n",
    "    \n",
    "                    #XTest['ExpectedMLT Separated Monetary'+str(predictDate)]  = separatedXTest[\"predictResult\"]\n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                \"Period\" : predictDate,\n",
    "                \"Model\": \"Monetary Separated Model\",\n",
    "                \"Training Time (seconds)\": end_time - start_time\n",
    "\n",
    "            })      \n",
    "    \n",
    "    \n",
    "        if bauerModel:\n",
    "                \n",
    "                #bauerResults = individualTestProphet(dfBauer,weekID = calibrationDate)\n",
    "                bauerTrain = dfBauer[dfBauer[\"CustomerID\"].isin(XTrain.index)]\n",
    "                bauerTest = dfBauer[dfBauer[\"CustomerID\"].isin(XTest.index)]\n",
    "            \n",
    "                start_time = time.time()\n",
    "                bauerResults = MixedSolution(bauerTrain,bauerTest,calibrationDate,Ytrain,YTest)\n",
    "                end_time = time.time()\n",
    "                results.append({\n",
    "                    \"Period\" : predictDate,\n",
    "                    \"Model\": \"Mixed  Model\",\n",
    "                    \"Training Time (seconds)\": end_time - start_time\n",
    "    \n",
    "                })   \n",
    "                dfResultados = pd.merge(dfResultados,bauerResults,how = \"left\",\n",
    "                            left_index=True, right_index=True)\n",
    "                \n",
    "                #dfResultados['ExpectedBauerML '+str(target)+\" \"+str(i+4)] = bauerResults['ExpectedML '+str(target)+\" \"+str(i+4)]\n",
    "        \n",
    "        dfResultados = pd.merge(dfResultados,XTest.drop(np.append(trainingCols,bestColsName),axis = 1),how = \"left\",\n",
    "                            left_index=True, right_index=True)\n",
    "            #dfResultados[dfResultados['ExpectedML '+str(periodo + (intervalosPredicao*2))] < 0]= 0\n",
    "    if calculateENIAC:\n",
    "        dfResultados = PredictENIAC(dfResultados)\n",
    "        \n",
    "    dfResultados.fillna(-1,inplace = True)\n",
    "    return dfResultados\n",
    "\n",
    "#dfResultados\n",
    "dfResultados = executaSBBD()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40c708dc-7639-477c-9134-21459b691a93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculo do Pareto / ENIAC / BGNBD\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def PredictENIAC(dfResultados):\n",
    "    for periodo in range(minTraining,maxTraining,intervalosPredicao):\n",
    "        calibrationDate = periodo #8\n",
    "        #Validar com os próximos intervalos.\n",
    "        validationEnd = periodo + intervalosPredicao       #12 \n",
    "        predictDate = periodo + (intervalosPredicao*2)    #16\n",
    "        print(calibrationDate,validationEnd,predictDate)   \n",
    "    \n",
    "    \n",
    "        XTrain = summary_data_from_transaction_data(df[df[\"WeekID\"] <= calibrationDate], \n",
    "                                                   cID, cDate, \n",
    "                                                   monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        Ytrain = summary_data_from_transaction_data(df[df[\"WeekID\"] <= validationEnd], \n",
    "                                                    cID, \n",
    "                                                    cDate, \n",
    "                                                    monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia)\n",
    "    \n",
    "        Ytrain = Ytrain.rename(columns={\"frequency\" : \"frequency_holdout\", \"monetary_value\" : \"monetary_holdout\"})[[\"frequency_holdout\",\"monetary_holdout\"]]\n",
    "    \n",
    "        \n",
    "        XTest = summary_data_from_transaction_data(df[df[\"WeekID\"] <= validationEnd], cID, cDate, monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        YTest = summary_data_from_transaction_data(df[df[\"WeekID\"] <= predictDate], cID, cDate, monetary_value_col = cMonetary,\n",
    "                                                   freq = frequencia\n",
    "                                                  )\n",
    "        \n",
    "        YTest = YTest.rename(columns={\"frequency\" : \"frequency_holdout\", \"monetary_value\" : \"monetary_holdout\"})[[\"frequency_holdout\",\"monetary_holdout\"]]\n",
    "        \n",
    "        #XTrain = pd.concat([XTrain, Ytrain], axis=1, join=\"inner\")\n",
    "        #XTest = pd.concat([XTest, YTest], axis=1, join=\"inner\")\n",
    "        XTrain = pd.merge(XTrain, Ytrain,how='inner',left_index=True, right_index=True)\n",
    "        XTest = pd.merge(XTest, YTest,how='inner',left_index=True, right_index=True)\n",
    "        if calculateTransactions:\n",
    "            start_time = time.time()\n",
    "            print(f\"Periodo {periodo} de {maxTraining}\\n\\n\")\n",
    "            #print(\"Criando modelo BG/NBD\")\n",
    "            modelBGF = criarModeloBGF(XTrain, teste = False,penalizer = penalizer)\n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                    \"Period\" : predictDate,\n",
    "                    \"Model\": \"BGF \",\n",
    "                    \"Training Time (seconds)\": end_time - start_time\n",
    "    \n",
    "                })   \n",
    "            #print(modelBGF)\n",
    "            start_time = time.time()\n",
    "           # print(\"Criando modelo Pareto\")\n",
    "            modelPareto = criarModeloPareto(XTrain,teste = False,penalizer = penalizer)\n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                    \"Period\" : predictDate,\n",
    "                    \"Model\": \"Pareto \",\n",
    "                    \"Training Time (seconds)\": end_time - start_time\n",
    "    \n",
    "                })    \n",
    "            print(modelPareto)\n",
    "            end = time.time()\n",
    "            #print(\"Tempo Pareto: \",timedelta(seconds = end - start))\n",
    "    \n",
    "            start_time = time.time()\n",
    "            modelML = escolheModelo(XTrain,target = 'frequency_holdout')\n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                    \"Period\" : predictDate,\n",
    "                    \"Model\": \"Transactions ENIAC\",\n",
    "                    \"Training Time (seconds)\": end_time - start_time\n",
    "    \n",
    "                })   \n",
    "            #print(\"Tempo ML: \",timedelta(seconds = end - start))\n",
    "    \n",
    "            \n",
    "            XTest['Expected ENIAC Transactions '+str(predictDate)] = modelML.predict(XTest[['frequency', 'recency', 'T', 'monetary_value']])\n",
    "            #XTest['Real Expected Transactions'+str(predictDate)] = YTest['frequency_holdout']\n",
    "            XTest['Expected Pareto '+str(predictDate)] = comprasEsperadas(modelPareto, XTest,numPeriodos = 7*intervalosPredicao,teste = False)\n",
    "            XTest['Expected BGF '+str(predictDate)] = comprasEsperadas(modelBGF, XTest,numPeriodos = 7*intervalosPredicao,teste = False)\n",
    "    \n",
    "            #dfResultados[dfResultados['ExpectedML '+str(periodo + (intervalosPredicao*2))] < 0]= 0\n",
    "        if calculateMonetary:\n",
    "            start_time = time.time()\n",
    "            ggf = preverValorGGF(XTrain, #Dataset já processado pelo RFM\n",
    "                   coefPenalizacao = penalizer, #Coeficiente de penalização utilizada pelo Gamma Gamma\n",
    "                   teste = False #Caso seja para efetuar a predição em um dataset com ou sem o período de observação\n",
    "                  )\n",
    "    \n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                    \"Period\" : predictDate,\n",
    "                    \"Model\": \"Gamma Gamma \",\n",
    "                    \"Training Time (seconds)\": end_time - start_time\n",
    "    \n",
    "                })  \n",
    "            XTest['Expected GGF '+str(predictDate)] = ggf.conditional_expected_average_profit(XTest[\"frequency\"], XTest[\"monetary_value\"]).values\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            modelML = escolheModelo(XTrain,target = 'monetary_holdout')\n",
    "            end_time = time.time()\n",
    "            results.append({\n",
    "                    \"Period\" : predictDate,\n",
    "                    \"Model\": \"Monetary ENIAC \",\n",
    "                    \"Training Time (seconds)\": end_time - start_time\n",
    "    \n",
    "                })   \n",
    "            #print(\"Tempo MLT: \",timedelta(seconds = end - start))\n",
    "            XTest['Expected ENIAC Monetary '+str(predictDate)] = modelML.predict(XTest[['frequency', 'recency', 'T', 'monetary_value']])\n",
    "            #XTest['Real Expected Monetary'+str(predictDate)] = YTest['monetary_holdout']\n",
    "    \n",
    "        dfResultados = pd.merge(dfResultados,XTest.drop(['frequency', 'recency', 'T', 'monetary_value', 'frequency_holdout',\n",
    "       'monetary_holdout'], axis = 1),how = \"left\",\n",
    "                            left_index=True, right_index=True)\n",
    "    return dfResultados\n",
    "        #dfResultados[dfResultados['ExpectedML '+str(periodo + (intervalosPredicao*2))] < 0]= 0    \n",
    "#return dfResultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21b067dc-37b4-477c-8a7e-df409b505156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Period                                Model  Training Time (seconds)\n",
      "0       16  Transactions Machine Learning Model                 4.403115\n",
      "1       16          Transactions Stacking Model                48.601633\n",
      "2       16         Transactions Separated Model                 7.690721\n",
      "3       16      Monetary Machine Learning Model                10.302720\n",
      "4       16              Monetary Stacking Model                85.991663\n",
      "5       16             Monetary Separated Model                 6.776051\n",
      "6       16                         Mixed  Model                15.382904\n",
      "7       20  Transactions Machine Learning Model                18.761425\n",
      "8       20          Transactions Stacking Model               106.749669\n",
      "9       20         Transactions Separated Model                 9.598503\n",
      "10      20      Monetary Machine Learning Model                 9.583206\n",
      "11      20              Monetary Stacking Model               101.297908\n",
      "12      20             Monetary Separated Model                10.124391\n",
      "13      20                         Mixed  Model                21.898540\n",
      "14      16                                 BGF                  0.253651\n",
      "15      16                              Pareto                 49.260871\n",
      "16      16                   Transactions ENIAC                 0.859003\n",
      "17      16                         Gamma Gamma                  0.028718\n",
      "18      16                      Monetary ENIAC                  0.978726\n",
      "19      20                                 BGF                  0.327961\n",
      "20      20                              Pareto                225.468356\n",
      "21      20                   Transactions ENIAC                 1.528235\n",
      "22      20                         Gamma Gamma                  0.034430\n",
      "23      20                      Monetary ENIAC                  1.638732\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7afbceb3-5afb-4dfe-9fdf-e5f013b34e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Time (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>Transactions Machine Learning Model</td>\n",
       "      <td>18.761425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>Transactions Stacking Model</td>\n",
       "      <td>106.749669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>Transactions Separated Model</td>\n",
       "      <td>9.598503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>Monetary Machine Learning Model</td>\n",
       "      <td>9.583206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>Monetary Stacking Model</td>\n",
       "      <td>101.297908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>Monetary Separated Model</td>\n",
       "      <td>10.124391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>Mixed  Model</td>\n",
       "      <td>21.898540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>BGF</td>\n",
       "      <td>0.327961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Pareto</td>\n",
       "      <td>225.468356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>Transactions ENIAC</td>\n",
       "      <td>1.528235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20</td>\n",
       "      <td>Gamma Gamma</td>\n",
       "      <td>0.034430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>Monetary ENIAC</td>\n",
       "      <td>1.638732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Period                                Model  Training Time (seconds)\n",
       "7       20  Transactions Machine Learning Model                18.761425\n",
       "8       20          Transactions Stacking Model               106.749669\n",
       "9       20         Transactions Separated Model                 9.598503\n",
       "10      20      Monetary Machine Learning Model                 9.583206\n",
       "11      20              Monetary Stacking Model               101.297908\n",
       "12      20             Monetary Separated Model                10.124391\n",
       "13      20                         Mixed  Model                21.898540\n",
       "19      20                                 BGF                  0.327961\n",
       "20      20                              Pareto                225.468356\n",
       "21      20                   Transactions ENIAC                 1.528235\n",
       "22      20                         Gamma Gamma                  0.034430\n",
       "23      20                      Monetary ENIAC                  1.638732"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"Period\"] == indexOfComparisson]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6be76cb-74d1-4568-95d2-71e0a4ee4bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Prediction 13</th>\n",
       "      <th>Prediction 14</th>\n",
       "      <th>Prediction 15</th>\n",
       "      <th>Prediction 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.509468</td>\n",
       "      <td>0.540587</td>\n",
       "      <td>0.501092</td>\n",
       "      <td>0.501092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.781136</td>\n",
       "      <td>0.781136</td>\n",
       "      <td>0.938070</td>\n",
       "      <td>0.791242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.670885</td>\n",
       "      <td>0.631389</td>\n",
       "      <td>0.631389</td>\n",
       "      <td>0.631389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.781136</td>\n",
       "      <td>0.781136</td>\n",
       "      <td>0.938070</td>\n",
       "      <td>0.791242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52474</th>\n",
       "      <td>52474</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52475</th>\n",
       "      <td>52475</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52476</th>\n",
       "      <td>52476</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52477</th>\n",
       "      <td>52477</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52478</th>\n",
       "      <td>52478</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.101182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52479 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Prediction 13  Prediction 14  Prediction 15  Prediction 16\n",
       "0               0       0.509468       0.540587       0.501092       0.501092\n",
       "1               1       0.781136       0.781136       0.938070       0.791242\n",
       "2               2       0.670885       0.631389       0.631389       0.631389\n",
       "3               3       0.781136       0.781136       0.938070       0.791242\n",
       "4               4       0.101182       0.101182       0.101182       0.101182\n",
       "...           ...            ...            ...            ...            ...\n",
       "52474       52474       0.101182       0.101182       0.101182       0.101182\n",
       "52475       52475       0.101182       0.101182       0.101182       0.101182\n",
       "52476       52476       0.101182       0.101182       0.101182       0.101182\n",
       "52477       52477       0.101182       0.101182       0.101182       0.101182\n",
       "52478       52478       0.101182       0.101182       0.101182       0.101182\n",
       "\n",
       "[52479 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9b9a1dd-fcc0-454e-99b6-bbdb69e1cab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'True 20'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'True 20'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### dfResultados\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m BauerT \u001b[38;5;241m=\u001b[39m retornarMétricas( \u001b[43mYt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrue \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindexOfComparisson\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,Xt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(indexOfComparisson)])\n\u001b[1;32m      3\u001b[0m BauerM \u001b[38;5;241m=\u001b[39m retornarMétricas( Ym[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(indexOfComparisson)],Xm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(indexOfComparisson)])\n\u001b[1;32m      6\u001b[0m MLT \u001b[38;5;241m=\u001b[39m retornarMétricas( dfResultados[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal Expected Transactions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(indexOfComparisson)],dfResultados[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpectedMLT \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(indexOfComparisson)])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'True 20'"
     ]
    }
   ],
   "source": [
    "### dfResultados\n",
    "BauerT = retornarMétricas( Yt['True '+str(indexOfComparisson)],Xt['Prediction '+str(indexOfComparisson)])\n",
    "BauerM = retornarMétricas( Ym['True '+str(indexOfComparisson)],Xm['Prediction '+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "MLT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['ExpectedMLT '+str(indexOfComparisson)])\n",
    "MLM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['ExpectedMLM '+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "MLTStacking = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['ExpectedMLT Stacking'+str(indexOfComparisson)])\n",
    "MLMStacking = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['ExpectedMLM Stacking'+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "MLTBasedT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['Expected Mixed frequency_holdout '+str(indexOfComparisson)])\n",
    "MLTBasedM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['Expected Mixed monetary_holdout '+str(indexOfComparisson)])\n",
    "\n",
    "#BauerBasedT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['ExpectedML numberOfOrders '+str(indexOfComparisson)])\n",
    "#BauerBasedM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['ExpectedML meanOrderProfit '+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "MLTBasedSeparatedT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['ExpectedMLT Separated Transactions'+str(indexOfComparisson)])\n",
    "MLTBasedSeparatedM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['ExpectedMLT Separated Monetary'+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "ENIACT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['Expected ENIAC Transactions '+str(indexOfComparisson)])\n",
    "ENIACM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['Expected ENIAC Monetary '+str(indexOfComparisson)])\n",
    "\n",
    "PARETO = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['Expected Pareto '+str(indexOfComparisson)])\n",
    "BGNBD = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['Expected BGF '+str(indexOfComparisson)])\n",
    "\n",
    "GG = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['Expected GGF '+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "solucoes = {\n",
    "    \"Bauer Transaction\" : BauerT,\n",
    "    \"Bauer Monetary\" : BauerM,\n",
    "    \n",
    "    \"ML T BASED Transactions\" : MLT,\n",
    "    \"ML T BASED Monetary\" : MLM,\n",
    " \n",
    "    \n",
    "    \"ML-T-Based (Bauer) Transactions\" : MLTBasedT,\n",
    "    \"ML-T-Based (Bauer) Monetary\" : MLTBasedM,\n",
    "\n",
    "    #\"ML-T-Based (Bauer) Transactions\" : BauerBasedT,\n",
    "    #\"ML-T-Based (Bauer) Monetary\" : BauerBasedM,\n",
    "    \n",
    "    \"ML T BASED SEPARATED Transactions\" : MLTBasedSeparatedT,\n",
    "    \"ML T BASED SEPARATED Monetary\" : MLTBasedSeparatedM, \n",
    "   \n",
    "    \"ML-RFM-Based (Eniac) Transactions\" : ENIACT,\n",
    "    \"ML-RFM-Based (Eniac)  Monetary\" : ENIACM,\n",
    "    \n",
    "    \"PARETO\" : PARETO,\n",
    "    \"BGNBD\" : BGNBD,\n",
    "    \"Gamma-Gamma\" : GG,\n",
    "\n",
    "    \"Stacking Transactions\" : MLTStacking,\n",
    "    \"Stacking Monetary\" : MLMStacking\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(solucoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c3bcf3d-1cb7-47fa-8874-8cb8bb4f5cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bauer Transaction</th>\n",
       "      <th>BGNBD</th>\n",
       "      <th>PARETO</th>\n",
       "      <th>ML-RFM-Based (Eniac) Transactions</th>\n",
       "      <th>ML-T-Based (Bauer) Transactions</th>\n",
       "      <th>ML T BASED Transactions</th>\n",
       "      <th>ML T BASED SEPARATED Transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_squared_error</th>\n",
       "      <td>1.092878</td>\n",
       "      <td>2.331434</td>\n",
       "      <td>2.355548</td>\n",
       "      <td>0.102876</td>\n",
       "      <td>0.116578</td>\n",
       "      <td>0.101414</td>\n",
       "      <td>1.460546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>0.785573</td>\n",
       "      <td>1.19543</td>\n",
       "      <td>1.207181</td>\n",
       "      <td>0.172326</td>\n",
       "      <td>0.11315</td>\n",
       "      <td>0.159464</td>\n",
       "      <td>0.400022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>-0.202417</td>\n",
       "      <td>-0.434604</td>\n",
       "      <td>-0.449443</td>\n",
       "      <td>0.936697</td>\n",
       "      <td>0.928266</td>\n",
       "      <td>0.937597</td>\n",
       "      <td>0.10128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_error</th>\n",
       "      <td>4.691781</td>\n",
       "      <td>4.435858</td>\n",
       "      <td>4.439397</td>\n",
       "      <td>1.963701</td>\n",
       "      <td>2.003156</td>\n",
       "      <td>1.897438</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <td>1.045408</td>\n",
       "      <td>1.526903</td>\n",
       "      <td>1.534779</td>\n",
       "      <td>0.320743</td>\n",
       "      <td>0.341436</td>\n",
       "      <td>0.318456</td>\n",
       "      <td>1.20853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intervaloConfiancaErros</th>\n",
       "      <td>(0.7086151772421214, 0.8625305423995617)</td>\n",
       "      <td>(1.0890970298838005, 1.3017630666658278)</td>\n",
       "      <td>(1.1010911786693143, 1.3132712554832637)</td>\n",
       "      <td>(0.1420452946724678, 0.20260707942897793)</td>\n",
       "      <td>(0.07708996547912596, 0.14920911539606174)</td>\n",
       "      <td>(0.12860859455872287, 0.19032029865746042)</td>\n",
       "      <td>(0.27236874299226643, 0.5276759475851)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Bauer Transaction  \\\n",
       "mean_squared_error                                       1.092878   \n",
       "mean_absolute_error                                      0.785573   \n",
       "r2_score                                                -0.202417   \n",
       "max_error                                                4.691781   \n",
       "root_mean_squared_error                                  1.045408   \n",
       "intervaloConfiancaErros  (0.7086151772421214, 0.8625305423995617)   \n",
       "\n",
       "                                                            BGNBD  \\\n",
       "mean_squared_error                                       2.331434   \n",
       "mean_absolute_error                                       1.19543   \n",
       "r2_score                                                -0.434604   \n",
       "max_error                                                4.435858   \n",
       "root_mean_squared_error                                  1.526903   \n",
       "intervaloConfiancaErros  (1.0890970298838005, 1.3017630666658278)   \n",
       "\n",
       "                                                           PARETO  \\\n",
       "mean_squared_error                                       2.355548   \n",
       "mean_absolute_error                                      1.207181   \n",
       "r2_score                                                -0.449443   \n",
       "max_error                                                4.439397   \n",
       "root_mean_squared_error                                  1.534779   \n",
       "intervaloConfiancaErros  (1.1010911786693143, 1.3132712554832637)   \n",
       "\n",
       "                                 ML-RFM-Based (Eniac) Transactions  \\\n",
       "mean_squared_error                                        0.102876   \n",
       "mean_absolute_error                                       0.172326   \n",
       "r2_score                                                  0.936697   \n",
       "max_error                                                 1.963701   \n",
       "root_mean_squared_error                                   0.320743   \n",
       "intervaloConfiancaErros  (0.1420452946724678, 0.20260707942897793)   \n",
       "\n",
       "                                    ML-T-Based (Bauer) Transactions  \\\n",
       "mean_squared_error                                         0.116578   \n",
       "mean_absolute_error                                         0.11315   \n",
       "r2_score                                                   0.928266   \n",
       "max_error                                                  2.003156   \n",
       "root_mean_squared_error                                    0.341436   \n",
       "intervaloConfiancaErros  (0.07708996547912596, 0.14920911539606174)   \n",
       "\n",
       "                                            ML T BASED Transactions  \\\n",
       "mean_squared_error                                         0.101414   \n",
       "mean_absolute_error                                        0.159464   \n",
       "r2_score                                                   0.937597   \n",
       "max_error                                                  1.897438   \n",
       "root_mean_squared_error                                    0.318456   \n",
       "intervaloConfiancaErros  (0.12860859455872287, 0.19032029865746042)   \n",
       "\n",
       "                              ML T BASED SEPARATED Transactions  \n",
       "mean_squared_error                                     1.460546  \n",
       "mean_absolute_error                                    0.400022  \n",
       "r2_score                                                0.10128  \n",
       "max_error                                                   7.0  \n",
       "root_mean_squared_error                                 1.20853  \n",
       "intervaloConfiancaErros  (0.27236874299226643, 0.5276759475851)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions =  {    \n",
    "    \"Bauer Transaction\" : BauerT,\n",
    "    \"BGNBD\" : BGNBD,\n",
    "    \"PARETO\" : PARETO,\n",
    "    \"ML-RFM-Based (Eniac) Transactions\" : ENIACT,\n",
    "    \"ML-T-Based (Bauer) Transactions\" : MLTBasedT,\n",
    "    \"ML T BASED Transactions\" : MLT,\n",
    "    \"ML T BASED SEPARATED Transactions\" : MLTBasedSeparatedT,\n",
    "\n",
    "}\n",
    "\n",
    "pd.DataFrame(transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202f7dab-45b1-43f6-8671-efacaa1872a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bauer Monetary</th>\n",
       "      <th>Gamma-Gamma</th>\n",
       "      <th>ML-RFM-Based (Eniac) Monetary</th>\n",
       "      <th>ML-T-Based (Bauer) Monetary</th>\n",
       "      <th>ML T BASED Monetary</th>\n",
       "      <th>ML T BASED SEPARATED Monetary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_squared_error</th>\n",
       "      <td>50.407692</td>\n",
       "      <td>670.078418</td>\n",
       "      <td>8.250426</td>\n",
       "      <td>12.66393</td>\n",
       "      <td>8.455589</td>\n",
       "      <td>20.757695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>6.198657</td>\n",
       "      <td>22.936792</td>\n",
       "      <td>1.524351</td>\n",
       "      <td>1.395802</td>\n",
       "      <td>1.647164</td>\n",
       "      <td>1.893588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>-0.8981</td>\n",
       "      <td>-411.320305</td>\n",
       "      <td>0.902102</td>\n",
       "      <td>0.849732</td>\n",
       "      <td>0.899667</td>\n",
       "      <td>0.753692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_error</th>\n",
       "      <td>19.8155</td>\n",
       "      <td>54.178721</td>\n",
       "      <td>26.074633</td>\n",
       "      <td>27.362438</td>\n",
       "      <td>24.519953</td>\n",
       "      <td>23.654633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <td>7.099837</td>\n",
       "      <td>25.885873</td>\n",
       "      <td>2.872356</td>\n",
       "      <td>3.558642</td>\n",
       "      <td>2.90785</td>\n",
       "      <td>4.556061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intervaloConfiancaErros</th>\n",
       "      <td>(5.812406506761615, 6.5849065473877015)</td>\n",
       "      <td>(21.59363306501406, 24.279950433684967)</td>\n",
       "      <td>(1.2518408482869348, 1.7968610994232257)</td>\n",
       "      <td>(1.0293787602859388, 1.762224945053996)</td>\n",
       "      <td>(1.3789256037403066, 1.915402961074806)</td>\n",
       "      <td>(1.4297309592509693, 2.3574445339728727)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Bauer Monetary  \\\n",
       "mean_squared_error                                     50.407692   \n",
       "mean_absolute_error                                     6.198657   \n",
       "r2_score                                                 -0.8981   \n",
       "max_error                                                19.8155   \n",
       "root_mean_squared_error                                 7.099837   \n",
       "intervaloConfiancaErros  (5.812406506761615, 6.5849065473877015)   \n",
       "\n",
       "                                                     Gamma-Gamma  \\\n",
       "mean_squared_error                                    670.078418   \n",
       "mean_absolute_error                                    22.936792   \n",
       "r2_score                                             -411.320305   \n",
       "max_error                                              54.178721   \n",
       "root_mean_squared_error                                25.885873   \n",
       "intervaloConfiancaErros  (21.59363306501406, 24.279950433684967)   \n",
       "\n",
       "                                    ML-RFM-Based (Eniac) Monetary  \\\n",
       "mean_squared_error                                       8.250426   \n",
       "mean_absolute_error                                      1.524351   \n",
       "r2_score                                                 0.902102   \n",
       "max_error                                               26.074633   \n",
       "root_mean_squared_error                                  2.872356   \n",
       "intervaloConfiancaErros  (1.2518408482869348, 1.7968610994232257)   \n",
       "\n",
       "                                     ML-T-Based (Bauer) Monetary  \\\n",
       "mean_squared_error                                      12.66393   \n",
       "mean_absolute_error                                     1.395802   \n",
       "r2_score                                                0.849732   \n",
       "max_error                                              27.362438   \n",
       "root_mean_squared_error                                 3.558642   \n",
       "intervaloConfiancaErros  (1.0293787602859388, 1.762224945053996)   \n",
       "\n",
       "                                             ML T BASED Monetary  \\\n",
       "mean_squared_error                                      8.455589   \n",
       "mean_absolute_error                                     1.647164   \n",
       "r2_score                                                0.899667   \n",
       "max_error                                              24.519953   \n",
       "root_mean_squared_error                                  2.90785   \n",
       "intervaloConfiancaErros  (1.3789256037403066, 1.915402961074806)   \n",
       "\n",
       "                                    ML T BASED SEPARATED Monetary  \n",
       "mean_squared_error                                      20.757695  \n",
       "mean_absolute_error                                      1.893588  \n",
       "r2_score                                                 0.753692  \n",
       "max_error                                               23.654633  \n",
       "root_mean_squared_error                                  4.556061  \n",
       "intervaloConfiancaErros  (1.4297309592509693, 2.3574445339728727)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monetary =  {    \n",
    "    \"Bauer Monetary\" : BauerM,\n",
    "    \"Gamma-Gamma\" : GG,\n",
    "    \"ML-RFM-Based (Eniac) Monetary\" : ENIACM,\n",
    "    \"ML-T-Based (Bauer) Monetary\" : MLTBasedM,\n",
    "    \"ML T BASED Monetary\" : MLM,\n",
    "    \"ML T BASED SEPARATED Monetary\" : MLTBasedSeparatedM,\n",
    "\n",
    "}\n",
    "\n",
    "pd.DataFrame(monetary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc0789f-ce04-4309-91e0-d395b2463f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      35.068626\n",
       "1      35.068626\n",
       "2      35.068626\n",
       "3      35.068626\n",
       "4      35.068626\n",
       "         ...    \n",
       "307    35.071751\n",
       "308    35.079002\n",
       "309    35.068626\n",
       "310    35.068626\n",
       "311    35.068626\n",
       "Name: Prediction 72, Length: 312, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt['Prediction '+str(indexOfComparisson)] * Xm['Prediction '+str(indexOfComparisson)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34e55fd5-4037-46f6-84f3-e7f835384294",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt.fillna(-1,inplace = True)\n",
    "Xm.fillna(-1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95bb724a-766d-4ac0-bf7d-7775ba20ba31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bauer</th>\n",
       "      <th>ENIAC</th>\n",
       "      <th>BauerBased</th>\n",
       "      <th>Solution</th>\n",
       "      <th>Segregated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_squared_error</th>\n",
       "      <td>250.537227</td>\n",
       "      <td>47.466182</td>\n",
       "      <td>56.68653</td>\n",
       "      <td>44.687807</td>\n",
       "      <td>235.047258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>13.418564</td>\n",
       "      <td>4.065849</td>\n",
       "      <td>3.173015</td>\n",
       "      <td>3.821963</td>\n",
       "      <td>5.744614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>-0.080644</td>\n",
       "      <td>0.939308</td>\n",
       "      <td>0.927518</td>\n",
       "      <td>0.94286</td>\n",
       "      <td>0.699459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_error</th>\n",
       "      <td>41.659501</td>\n",
       "      <td>38.373836</td>\n",
       "      <td>42.656674</td>\n",
       "      <td>39.326655</td>\n",
       "      <td>98.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <td>15.828368</td>\n",
       "      <td>6.88957</td>\n",
       "      <td>7.529046</td>\n",
       "      <td>6.684894</td>\n",
       "      <td>15.331251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intervaloConfiancaErros</th>\n",
       "      <td>(12.481881479784438, 14.355246025902357)</td>\n",
       "      <td>(3.4432635293837235, 4.688433607297951)</td>\n",
       "      <td>(2.408734940485837, 3.9372946109231264)</td>\n",
       "      <td>(3.2080383653315767, 4.435887643168017)</td>\n",
       "      <td>(4.153508222378384, 7.335719872437433)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Bauer  \\\n",
       "mean_squared_error                                     250.537227   \n",
       "mean_absolute_error                                     13.418564   \n",
       "r2_score                                                -0.080644   \n",
       "max_error                                               41.659501   \n",
       "root_mean_squared_error                                 15.828368   \n",
       "intervaloConfiancaErros  (12.481881479784438, 14.355246025902357)   \n",
       "\n",
       "                                                           ENIAC  \\\n",
       "mean_squared_error                                     47.466182   \n",
       "mean_absolute_error                                     4.065849   \n",
       "r2_score                                                0.939308   \n",
       "max_error                                              38.373836   \n",
       "root_mean_squared_error                                  6.88957   \n",
       "intervaloConfiancaErros  (3.4432635293837235, 4.688433607297951)   \n",
       "\n",
       "                                                      BauerBased  \\\n",
       "mean_squared_error                                      56.68653   \n",
       "mean_absolute_error                                     3.173015   \n",
       "r2_score                                                0.927518   \n",
       "max_error                                              42.656674   \n",
       "root_mean_squared_error                                 7.529046   \n",
       "intervaloConfiancaErros  (2.408734940485837, 3.9372946109231264)   \n",
       "\n",
       "                                                        Solution  \\\n",
       "mean_squared_error                                     44.687807   \n",
       "mean_absolute_error                                     3.821963   \n",
       "r2_score                                                 0.94286   \n",
       "max_error                                              39.326655   \n",
       "root_mean_squared_error                                 6.684894   \n",
       "intervaloConfiancaErros  (3.2080383653315767, 4.435887643168017)   \n",
       "\n",
       "                                                     Segregated  \n",
       "mean_squared_error                                   235.047258  \n",
       "mean_absolute_error                                    5.744614  \n",
       "r2_score                                               0.699459  \n",
       "max_error                                                  98.2  \n",
       "root_mean_squared_error                               15.331251  \n",
       "intervaloConfiancaErros  (4.153508222378384, 7.335719872437433)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResultados[\"ENIAC LTV \"+str(indexOfComparisson)] = dfResultados['Expected ENIAC Monetary '+str(indexOfComparisson)] * (dfResultados['Expected ENIAC Transactions '+str(indexOfComparisson)])\n",
    "dfResultados[\"Real LTV \"+str(indexOfComparisson)] =  dfResultados['Real Expected Monetary'+str(indexOfComparisson)] * dfResultados['Real Expected Transactions'+str(indexOfComparisson)]\n",
    "dfResultados[\"Segregated LTV \"+str(indexOfComparisson)] =  dfResultados['ExpectedMLT Separated Monetary'+str(indexOfComparisson)] * dfResultados['ExpectedMLT Separated Transactions'+str(indexOfComparisson)]\n",
    "dfResultados[\"ML Soluction \"+str(indexOfComparisson)] =  dfResultados['ExpectedMLM '+str(indexOfComparisson)] * dfResultados['ExpectedMLT '+str(indexOfComparisson)]\n",
    "dfResultados[\"Bauer Based LTV \"+str(indexOfComparisson)] =  dfResultados['Expected Mixed monetary_holdout '+str(indexOfComparisson)] * dfResultados['Expected Mixed frequency_holdout '+str(indexOfComparisson)]\n",
    "Xt[\"LTV \"+str(indexOfComparisson)] =  Xt['Prediction '+str(indexOfComparisson)] * Xm['Prediction '+str(indexOfComparisson)]\n",
    "Yt[\"LTV \"+str(indexOfComparisson)] =  Yt['True '+str(indexOfComparisson)] * Ym['True '+str(indexOfComparisson)]\n",
    "Xt.fillna(-1,inplace = True)\n",
    "Yt.fillna(-1,inplace = True)\n",
    "\n",
    "\n",
    "#dfResultados[\"Mixed LTV \"+str(indexOfComparisson)] =  dfResultados['Real Expected Monetary'+str(indexOfComparisson)] * dfResultados['Real Expected Transactions'+str(indexOfComparisson)]\n",
    "#dfResultados[\"Mixed LTV \"+str(indexOfComparisson)] =  dfResultados['Expected Mixed monetary_holdout '+str(indexOfComparisson)] * dfResultados['Expected ENIAC Transactions '+str(indexOfComparisson)]\n",
    "\n",
    "\n",
    "ENIAC = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['ENIAC LTV '+str(indexOfComparisson)])\n",
    "MLSolution = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['ML Soluction '+str(indexOfComparisson)])\n",
    "BauerBased = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['Bauer Based LTV '+str(indexOfComparisson)])\n",
    "Segregated = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['Segregated LTV '+str(indexOfComparisson)])\n",
    "Bauer = retornarMétricas( Yt[\"LTV \"+str(indexOfComparisson)],Xt[\"LTV \"+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "\n",
    "solucoesLTV = {\n",
    "    \"Bauer\" : Bauer,\n",
    "    \"ENIAC\" : ENIAC,\n",
    "    \"BauerBased\" : BauerBased,\n",
    "    \"Solution\" : MLSolution,\n",
    "    \"Segregated\" : Segregated,\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(solucoesLTV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876727a7-d8aa-4d9d-af8b-eea5ca95e306",
   "metadata": {},
   "source": [
    "## Exportando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d29f89-fc3a-4fca-8dee-9d25e96c3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3681351-e95e-4653-855f-ddc061eb077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# checking if the directory demo_folder \n",
    "# exist or not. \n",
    "\n",
    "path = \"Results/\"+str(datasetName)\n",
    "if not os.path.exists(path): \n",
    "\tos.makedirs(path)\n",
    "\n",
    "pd.DataFrame(solucoesLTV).to_csv(path+\"/TabelaLTV.csv\")\n",
    "pd.DataFrame(solucoes).to_csv(path+\"/TabelaTransactionsMonetary.csv\")\n",
    "dfResultados.to_csv(path+\"/Resultados.csv\")\n",
    "results_df[results_df[\"Period\"] == indexOfComparisson].to_csv(path+\"/TempoExecut.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae53ecc-dce7-4a5d-9b50-e3effe6df39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ENIACBoostedT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['ExpectedMLT '+str(indexOfComparisson)])\n",
    "ENIACBoostedM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['ExpectedMLM '+str(indexOfComparisson)])\n",
    "\n",
    "ENIACStackingT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['ExpectedMLT Stacking'+str(indexOfComparisson)])\n",
    "ENIACStackingM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['ExpectedMLM Stacking'+str(indexOfComparisson)])\n",
    "\n",
    "MLTBasedSeparatedT = retornarMétricas( dfResultados['Real Expected Transactions'+str(indexOfComparisson)],dfResultados['ExpectedMLT Separated Transactions'+str(indexOfComparisson)])\n",
    "MLTBasedSeparatedM = retornarMétricas( dfResultados['Real Expected Monetary'+str(indexOfComparisson)],dfResultados['ExpectedMLT Separated Monetary'+str(indexOfComparisson)])\n",
    "\n",
    "\n",
    "\n",
    "solucoes = {\n",
    "    \"ENIAC Transactions\" : ENIACT,\n",
    "    \"MLT\" : MLT,\n",
    "    \"ENIACBoosted Transactions\" : ENIACBoostedT,\n",
    "    \"ENIAC Stacking Transactions\" : ENIACStackingT,\n",
    "    #\"ML T BASED SEPARATED Transactions\" : MLTBasedSeparatedT,\n",
    "    #\"ML T BASED SEPARATED Monetary\" : MLTBasedSeparatedM,  \n",
    "    \"ENIAC  Monetary\" : ENIACM,\n",
    "    \"ENIACBoosted Monetary\" : ENIACBoostedM,\n",
    "    \"ENIAC Stacking Monetary\" : ENIACStackingM,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(solucoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf0066-510a-4be5-8298-99c8fceacf10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfResultados[\"ENIAC LTV \"+str(indexOfComparisson)] = dfResultados['Expected ENIAC Monetary '+str(indexOfComparisson)] * (dfResultados['Expected ENIAC Transactions '+str(indexOfComparisson)])\n",
    "dfResultados[\"ENIAC Boosted LTV \"+str(indexOfComparisson)] = dfResultados['ExpectedMLM '+str(indexOfComparisson)] * (dfResultados['ExpectedMLT '+str(indexOfComparisson)])\n",
    "dfResultados[\"Real LTV \"+str(indexOfComparisson)] =  dfResultados['Real Expected Monetary'+str(indexOfComparisson)] * dfResultados['Real Expected Transactions'+str(indexOfComparisson)]\n",
    "dfResultados[\"ENIAC Stack LTV \"+str(indexOfComparisson)] = dfResultados['ExpectedMLM Stacking'+str(indexOfComparisson)] * (dfResultados['ExpectedMLT Stacking'+str(indexOfComparisson)])\n",
    "dfResultados[\"Segregated LTV \"+str(indexOfComparisson)] =  dfResultados['ExpectedMLT Separated Monetary'+str(indexOfComparisson)] * dfResultados['ExpectedMLT Separated Transactions'+str(indexOfComparisson)]\n",
    "\n",
    "\n",
    "ENIAC = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['ENIAC LTV '+str(indexOfComparisson)])\n",
    "ENIACB = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['ENIAC Boosted LTV '+str(indexOfComparisson)])\n",
    "ENIACS = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['ENIAC Stack LTV '+str(indexOfComparisson)])\n",
    "ENIACSegregated = retornarMétricas( dfResultados['Real LTV '+str(indexOfComparisson)],dfResultados['Segregated LTV '+str(indexOfComparisson)])\n",
    "\n",
    "solucoes = {\n",
    "    \"ENIAC\" : ENIAC,\n",
    "    \"ENIAC Boosted\" : ENIACB,\n",
    "    \"ENIAC Stacked\" : ENIACS,\n",
    "    \"ENIAC Segregated\" : ENIACSegregated,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(solucoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df0805-7d25-4be6-92de-5ea3a622e00e",
   "metadata": {},
   "source": [
    "## Análise dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5645c-efe9-4bf8-9fe1-0118b483b3fa",
   "metadata": {},
   "source": [
    "1. quantos meses tem cada uma das bases de dados\n",
    "2. quantos usuários tem cada uma das bases de dados\n",
    "3. quantas transações no total tem cada uma das bases de dados\n",
    "3. quantas transacoes por usuário (dividir total de transações pelo total de usuários) tem cada uma das bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b5565-218b-47eb-8b46-1fcfe468873c",
   "metadata": {},
   "source": [
    "### CDNow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbf9ac-ce2d-44a1-a717-559452c29794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weeks = dfBauer.WeekID.nunique()\n",
    "customers = dfBauer.CustomerID.nunique()\n",
    "numTransactions = dfUnprocesses.size\n",
    "userTransactions = dfUnprocesses.groupby(\"CustomerID\").ItemProfit.count()\n",
    "mediaTransacoes = userTransactions.mean()\n",
    "modaTransacao = userTransactions.mode().iloc[0]\n",
    "minTransaction = userTransactions.min()\n",
    "maxTransaction = userTransactions.max()\n",
    "\n",
    "metricas = {\n",
    "    \"Periodos (Semanas)\" : weeks,\n",
    "    \"Usuários\" : customers,\n",
    "    \"Total Transações\" : numTransactions,\n",
    "    \"Média Transações\" : mediaTransacoes,\n",
    "    \"Minímo de Transações\" : minTransaction,\n",
    "    \"Máximo de transações\" : maxTransaction,\n",
    "    \"Moda de transações\" : modaTransacao\n",
    "}\n",
    "metricas\n",
    "\n",
    "\n",
    "#pd.DataFrame(metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93c282-7930-4542-9bf0-d04d59f85627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9776b05-2fcd-4984-ad1f-7315e6797597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xt =  pd.read_csv(\"../Dados/Stacking/CDNOW/Prediction CDNOW numberOfOrders.csv\")\n",
    "Yt = pd.read_csv(\"../Dados/Stacking/CDNOW/True CDNOW numberOfOrders.csv\")\n",
    "\n",
    "Xm = pd.read_csv(\"../Dados/Stacking/CDNOW/Prediction CDNOW meanOrderProfit.csv\")\n",
    "Ym = pd.read_csv(\"../Dados/Stacking/CDNOW/True CDNOW meanOrderProfit.csv\")\n",
    "\n",
    "dfBauer = pd.read_csv(\"../Dados/Modelos Bauer/CDNOW_FINAL.csv\")\n",
    "\n",
    "dfUnprocesses = pd.read_csv(\"../Dados/Modelos Bauer/customerOrderDT_CDNOW Clean.csv\")\n",
    "dfUnprocesses['OrderDate'] = pd.to_datetime(dfUnprocesses['OrderDate'])\n",
    "dfUnprocesses.dropna(inplace = True)\n",
    "dfUnprocesses = dfUnprocesses[dfUnprocesses[\"CustomerID\"].isin(dfBauer.CustomerID.astype(int).values)]\n",
    "\n",
    "\n",
    "targetTimeLength = 4 \n",
    "seqInLength = 2*targetTimeLength\n",
    "seqOutLength = targetTimeLength\n",
    "training_start,training_end,holdout_start,holdout_end = getBauerDatasetSplitTimes(dfBauer.reset_index().WeekID,seqOutLength)\n",
    "targetTimeLength = holdout_end - holdout_start\n",
    "numSeqFeat = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"]).size\n",
    "seqFeatVec = dfBauer.columns.difference([\"CustomerID\",\"WeekID\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
